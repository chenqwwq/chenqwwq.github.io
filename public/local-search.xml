<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>MySQL 复习总结（残酷学习版</title>
    <link href="/2022/03/18/MySQL/"/>
    <url>/2022/03/18/MySQL/</url>
    
    <content type="html"><![CDATA[<h1><span id="mysql残酷学习版">MySQL（残酷学习版</span></h1><p>[TOC]</p><h2><span id="mysql-的整体架构">MySQL 的整体架构</span></h2><p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/MySQL%E7%9A%84%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84-7940422.png" alt="img"></p><h3><span id="连接器">连接器</span></h3><p>连接器就是负责管理连接的，包括权限验证等等流程，因为连接是 TCP 的可能还包括连接状态的维护。</p><h3><span id="分析器">分析器</span></h3><p>分析器的作用是对 SQL 进行词法分析，语法分析，抽出 BST，并交给后续的组件。</p><h3><span id="优化器">优化器</span></h3><p><strong>优化器是 MySQL 中对 SQL 语法的分析器以及索引的选择器，会根据解析出进来的 SQL 语句结合索引以及取样数据选择索引。</strong></p><p>因为其中还包含数据的影响，所以即使符合最左前缀匹配也无法 100% 确定是否真的会走索引。</p><p>例如，如果优化器根据数据推测全表扫描的速度大于走索引再回表的速度，那么就会直接放弃索引。</p><h3><span id="执行器">执行器</span></h3><p>执行器就相当于是一个调度器，会根据表选择的存储引擎调用不同的存储引擎的接口。</p><p>执行器对于上层的优化器屏蔽了底层不同存储引擎带来的查询语法上的差异性。</p><p>MySQL 的存储引擎是可插拔式的，在创建表的时候就可以使用不同的存储引擎。</p><p>早期的 MySQL 还会有查询缓存层，但是在4.x版本中就已经被删除了。</p><blockquote><p>Q: 为什么要删除查询缓存？</p></blockquote><p>查询缓存是以查询语句为 Key，作为命中的要求，所以命中率并不会高，而且大量的缓存在业务逻辑层实现灵活性更高，更加可控，也就实在没必要在数据库中增加缓存机制。</p><h2><span id="mysql-transaction事务">MySQL Transaction（事务</span></h2><p>事务的特性有如下四种，<strong>原子性（Atomicity），一致性（Consistency），隔离性（Isolation），持久性（Durability）</strong>。</p><p>原子性指的是事务的操作作为一个不可再分的整体，<strong>要不同时完成要不同时失败</strong>。</p><p>隔离性指的是<strong>多个事务并发执行的时候，互相之间的可见性</strong>，多个事务之间互相干扰的情况。</p><blockquote><p>隔离性并不是说强制的完全不能看到，类似 InnoDB 提供了多种的隔离级别，低级别隔离也有使用场景。</p></blockquote><p>持久性好理解，<strong>就是保证数据不丢失，在事务提交之后，事务造成的变更就是永久性的。</strong></p><p>一致性指的是事务执行的前后，数据库中的数据都处于一种稳定状态，可能不太好理解，简单举例可以参考转账的操作，转账前后总额是不会增加的。</p><h3><span id="innodb-下事务的隔离级别">InnoDB 下事务的隔离级别</span></h3><p>MySQL InnoDB 中提供了四种隔离级别：</p><ul><li>READ UNCOMMITTED 读未提交</li><li>READ COMMITED 读已提交</li><li>REPEATABLE READ 可重复读（Default）</li><li>SERIALIZABLE  序列化</li></ul><p>四种隔离级别分别解决了不同的并发问题：</p><table><thead><tr><th>隔离解别</th><th>脏读</th><th>不可重复读</th><th>幻读</th></tr></thead><tbody><tr><td>Read Uncommitted</td><td>Y</td><td>Y</td><td>Y</td></tr><tr><td>Read Committed</td><td>N</td><td>Y</td><td>Y</td></tr><tr><td>Repeatable(default)</td><td>N</td><td>N</td><td>Y（InnoDB - N）</td></tr><tr><td>Serializable</td><td>N</td><td>N</td><td>N</td></tr></tbody></table><blockquote><p>简单理解一下这三种并发问题：</p><p><strong>脏读（读未提交），事务读取到了其它事务中未提交的数据。</strong></p><p><strong>不可重复读，事务前后多次读取内容不一致。</strong></p><p><strong>幻读，事务前后多次读取总量不一致。</strong></p></blockquote><p><strong>RC  解决脏读依靠的就是锁和MVCC。</strong></p><blockquote><p>MVCC 在 InnoDB 的 RR 和 RC 级别下表现是不一样的，RR 级别下，MVCC 以第一次 SELECT 查到的数据为主不会再创建新的快照，但是 RC 级别下，MVCC 机制每次都会创建新的快照，所以也会存在前后数据不一致的情况。</p></blockquote><h3><span id="innodb-中-acid-的实现">InnoDB 中 ACID 的实现</span></h3><p>首先是原子性，<strong>InnoDB 使用 Undo Log 实现了原子性</strong>，基本原则就是在失败之后回滚之前的操作。</p><blockquote><p>InnoDB 的 Undo Log 会根据数据行的版本指针组成一个链表，回滚时可以根据链表向上追溯。</p></blockquote><p><strong>隔离性，InnoDB 的隔离性是依靠 MVCC 和 锁来实现的。</strong></p><p>InnoDB 中提供了多种不同的隔离级别，每个隔离级别使用不同类型的锁和 MVCC 表现形式来支持隔离性。</p><blockquote><p>锁定义了事务并发时访问权限，MVCC 减少了部分上锁的情况（主要还是增加性能。</p></blockquote><p><strong>持久性，InnoDB 中的持久性是依靠的 redo log 以及 undo log 实现的。</strong></p><blockquote><p>并说不清为什么还需要 undo log，但是因为 WAL 机制，redo log 是在数据修改前就已经持久化的，在事务提交的时候可以保证 redo log 已经落盘了，大部分情况下 redo log 就已经能保障数据的持久性了。</p></blockquote><p>一致性… emmm 不太清楚，应该是其他的东西一起保证的。</p><h3><span id="innodb-中的mvcc多版本并发控制">InnoDB 中的MVCC（多版本并发控制）</span></h3><p>MVCC（<strong>Multi-Version  Concurrency Control</strong>） 在我看来是 InnoDB 中一个非常重要的特性，很大程度上提高了 MySQL 的并发性能。</p><p>MVCC 机制在数据行中保留了多版本的数据，使用数据行隐藏字段 roll_pointer（回滚指针）串联起一个版本链，可以顺着版本链回滚数据行。</p><blockquote><p>因为是链是逐个遍历直到找到当前事务可以看到的数据行，所以当链很长的时候可能会拖慢查询。</p></blockquote><p>基于 MVCC，InnoDB 引入了一个快照读的概念，相对应的还有当前读，快照读指的是当前查询语句读取的是快照的内容，当前读读取的就是当前的真实数据。</p><blockquote><p>这里的快照不同于 Redis 的 RDB，是基于隐藏字段 trx_id 实现的可读范围标识。 </p></blockquote><p>InnoDB 的行记录包含了两个隐藏字段：</p><table><thead><tr><th>字段名</th><th>含义</th></tr></thead><tbody><tr><td>trx_id</td><td>事务Id，由存储引擎统一下发，确保递增</td></tr><tr><td>roll_pointer</td><td>回滚指针</td></tr></tbody></table><p>回滚指针指向的是当前行上次的数据，以此形成一个版本链，如果需要回滚到最先版本的数据，需要顺着 roll_pointer 一直往上。</p><p><strong>MVCC 根据 trx_id 的大小界定出可见范围。</strong></p><p>事务开始时，会额外保存当前最大和最小的 trx_id，并且保存当前未提交的事务 trx_id 数组。</p><blockquote><p>这里的事务开始是指第一次查询，而非 start tran。</p></blockquote><p>小于最小的 trx_id 标识已经提交，所以可见，大于最大的 trx_id 表示开始时还未开启，所以不可见。</p><p>如果在中间，则判断 trx_id 数组是否包含来标识是否可读。</p><p><strong>MVCC 特性仅仅在 RC 和 RR 级别下生效，</strong>并且在两个级别下的表现形式不同。</p><p><strong>在 RC 级别下，每次查询都会创建一个快照，而在 RR 级别下，只有第一次查询会创建一个快照。</strong>（Important</p><blockquote><p>这就导致了事务的表现不同。</p><p>在 RC 级别下，事务可以查看到别的事务已经提交的数据，这样就造成了不可重复读，也无法避免脏读。</p><p>而在 RR 级别下，事务只会以第一次查询语句为准创建快照，所以 RR 级别下不会出现所谓的不可重复读问题。</p></blockquote><h3><span id="参考文档">参考文档</span></h3><ul><li><a href="https://mp.weixin.qq.com/s/dMErouLlrte84Nmb97MkTQ">相见恨晚，MVCC 这么理解，早就通关了</a></li><li><a href="https://draveness.me/mysql-transaction/">『浅入深出』MySQL 中事务的实现</a></li></ul><h2><span id="mysql-index索引">MySQL Index（索引</span></h2><p>索引就是用来加速查询速度的特殊结构。</p><h3><span id="innodb-中的索引结构">InnoDB 中的索引结构</span></h3><p><strong>常见的索引结构有B+树，B树或者 Hash 索引，倒排索引</strong>。</p><blockquote><p>InnoDB 中以B+树为主，存在自适应 Hash索引，提供特殊形式的查询优化。</p></blockquote><bf><p>B+ 树就是平衡的搜索树，可以简单理解为是二叉搜索树（BST）或者二叉平衡树（AVL）的变种。</p><p>AVL <strong>就是任意节点左右子树的高度差不超过1的树，</strong>为了维持这种特性需要大量的旋转操作（添加最多旋转两次，但是删除最多需要 Lg(N)，并且随着深度的增加搜索的效率也会慢慢降低，在动辄千万亿万的数据的数据库中，二叉搜索树明显是不合适的。</p><p>M 阶的B+树，根节点的节点数为[2,M]，索引节点的节点数为[M&#x2F;2,M]，<strong>而且保证了数据的有序性质</strong>，所以层次更低，查询速度更快也更平稳。</p><blockquote><p>因为B+树数据有序性的特点，所以如果不使用单调递增的索引键，在插入和删除操作时候就会存在页分裂和页合并的问题，十分影响效率。</p></blockquote><p>B 树和 B+树 的区别如下：</p><ol><li>B+ 树的所有数据都在子节点中，这样的<strong>查询更加稳定</strong>，所有的查询都需要树高度次的查询。</li><li>B+ 树所有的子节点<strong>组成一个链表</strong>，这样非常便于<strong>实现范围查询</strong>。</li></ol><p>相对于 B 树和 Hash 来说，B+树更加符合磁盘的特性。</p><blockquote><p>为什么说 B+ 树更加符合磁盘特性呢？</p></blockquote><p>相比于 Hash 来说，B+ 树的层级更低（往往只有三四层，对于 B+ 树的存储来说，往往一个节点就是一个数据页，因此正常情况下 3～4 次磁盘 IO 就可以获取到想要的内容，并且 B+ 树将所有的叶子节点连成链，更加适合范围查询。</p><p>相比于 B 树，除去叶子节点成链不说，B+ 树的非叶子节点不保存数据，具有更稳定的查询效率，B 树虽然在某些查询中可以更快速，但是整体查询并不稳定，读取同样大小的索引页 B+ 树有更多的索引项。</p><blockquote><p>MySQL 为什么不使用 Hash 表或者跳表作为索引实现？</p></blockquote><p>Hash 表只适合等值查询，几乎无法做范围查询。</p><blockquote><p>为什么不使用跳表的原因如下：</p></blockquote><p>MySQL 的主要数据还是保存在磁盘中，相对于跳表，B+ 树更加适配磁盘的特性，每个索引块可以保存在一个盘页。</p><p>（以 Redis 为例，如果纯内存的数据库跳表应该和 B+ 树访问速度差不多。</p><h3><span id="索引分类">索引分类</span></h3><h4><span id="聚集索引和非聚集索引">聚集索引和非聚集索引</span></h4><p>聚集索引并<strong>不是一种单独的索引类型，而是一种数据的存储方式</strong>，在 InnoDB 中，主键索引就是聚集索引，<strong>所有的数据都保存在主键索引的叶子节点中，数据按照主键的顺序排列存储。</strong></p><p>InnoDB 中，主键索引决定了数据的物理存储顺序，应该更能理解主键的乱序插入带来的页分裂等等问题了。</p><blockquote><p>如果没有明确定义表的主键，MySQL 也会挑选一个唯一键作为主键，如果没有唯一键则会生成一个 rowId 作为主键。</p></blockquote><p>非聚集索引就是非聚集索引，<strong>和聚集索引相反的它的逻辑顺序和物理的存储顺序就是完全无关的。</strong></p><p>InnoDB 的实现中，次级索引都是非聚集索引，保存的是主键。</p><blockquote><p>所以 InnoDB 中存在回表操作，就是在一个索引树中无法完全确定数据是否可用时，先返回主键，查询完整的数据再来判断。</p><p>增加单索引中字段，索引下推，索引联合都可以起到减少回表的作用。</p></blockquote><p>MyISAM 中的非聚集索引实现不同，MyISAM 中所有的索引树都是非聚集索引，包括主键在内，保存的都是数据的真实地址。</p><blockquote><p>MyISAM 和 InnoDB 的不同在这里就有体现：</p><p>MyISAM 支持没有主键，理论上来说 MyISAM 的主键索引和次级索引没有任何区别。</p><p>MyISAM 的索引中保存的都是数据地址，而 InnoDB 的次级索引保存的主键。</p></blockquote><h4><span id="稠密索引和稀疏索引">稠密索引和稀疏索引</span></h4><p>稠密索引会为每一个键值建立一个索引记录，可以i加快查询速度，但是需要更多的空战占用以及维护成本。（类似 MySQL 中的主键索引</p><p>稀疏索引不会为每一个键值建立索引，这种索引往往出现在有序的排序中，例如跳表结构就是稀疏索引的典型实现（Mongo 以及 Kafka 都算是稀疏索引，Mongo 的文档可能会缺失某些字段？Kafka 是以时间戳为序间隔一定长度建立索引项</p><h4><span id="唯一索引和非唯一索引">唯一索引和非唯一索引</span></h4><p>唯一索引就是在表内需要保证字段值全局唯一的索引。</p><blockquote><p>唯一索引是保证不重复调用或者记录唯一的有效手段。</p><p>比如希望点赞数不重复被记录，那么就可以将帖子Id和用户Id组成一个唯一索引，确保一个用户只能对一个帖子点赞一次。</p></blockquote><p>在 InnoDB 中唯一索引还会导致一些另外的问题，有好也有坏，但影响其实都不大，仅做了解：</p><ol><li>首先等值查询时，如果查找字段有唯一索引，那么查询到一条记录就会返回，而非唯一索引会顺着链表继续查询到一条不相等的记录。</li><li>在插入或者修改数据的时候，InnoDB 的 Change Buffer 可能有效的减少随机读操作，而唯一索引无法使用该特性，因为在修改或者插入前都需要判断是否唯一</li></ol><blockquote><p>Q：什么是 Change Buffer？</p></blockquote><p>Change Buffer 早期又称为 Insert Buffer，在数据插入时生效，后面扩展到数据的修改。</p><p>Change Buffer 主要优化非唯一辅助索引的维护成本。</p><p>在涉及到数据修改时，如果记录所在数据页在内存中则直接修改，如果不在可能需要先加载再修改，此时这个加载过程就是随机读的过程，相对于顺序读而言随机读的效率低了不止一点点。</p><p>所以在修改的时候，InnoDB 会把这些更新操作缓存到 Changge Buffer 中，日志正常保存，即使宕机也能根据日志恢复。</p><p>保存在 Change Buffer 的数据在下一次读取到数据页时合并，也就是 Merge 过程。</p><h4><span id="前缀索引">前缀索引</span></h4><p>前缀索引是指在一个长字符串字段中，可以选取其中N字节长度的前缀作为索引。</p><blockquote><p>长字符串的索引除了使用前缀索引，还可以直接独立一个字段做hash，搜索会更加全面。</p></blockquote><h3><span id="索引使用的相关算法">索引使用的相关算法</span></h3><h4><span id="最左前缀匹配">最左前缀匹配</span></h4><p>最左前缀匹配在联合索引中是一个非常重要的概念，<strong>就是依据左前缀判断是否可以使用该索引。</strong></p><blockquote><p>简单的例子，联合索引[a,b,c]，可是使用该索引的查询条件是[a]，[a,b]，[a,b,c]，但是绝对不包括[b,c]等不以a开头的查询条件</p></blockquote><p>本质上来说，联合索引在 InnoDB 中的数据结构仍然是一棵 B+ 树，并且索引节点保存以声明顺序所表示的索引数据。</p><blockquote><p>例如[a,b,c]，在索引树中的排序就是先按照a排序，a相同按照b排序，b相同按照c排序。</p><p>！！！利用索引有序的结构，可以完美的优化查询语句中的排序，但是在联合索引中，如果搜索条件是[a,b]并且按照b排序就不会出现文件排序，因为在a相同时，b本身就是有序的。</p><p>但是在搜索条件为[a,c]时，当a相同时，c并非有序，所以查询会出现 file sort。</p></blockquote><h4><span id="覆盖索引">覆盖索引</span></h4><p>覆盖索引是指在索引树中的内容已经包含了需要查找所需要所有字段，所以可以直接返回而跳过回表。</p><blockquote><p>回表可以简单理解为使用二级索引查询获得主键之后，为了获得更多的数据而需要再一次扫描主键索引树。</p><p>！！一般来说扫描二级索引树获得的主键，会返回给 Server 层，由 Server 再次发起查询。</p></blockquote><p>有些时候大量的回表会导致查询的效率十分低下，此时适当冗余索引字段也不失为一个好办法。</p><h4><span id="索引下推">索引下推</span></h4><p>索引下推是在 MySQL 5.6 引入的对索引使用方式的优化，在次级索引树的遍历过程中，尽量多的使用索引树中的字段。</p><blockquote><p>在5.6之前，[a,b,c]索引查询[a,c]，只能使用到a字段，c字段就需要回表之后判断，如果a的筛率不高就会有大量的回表，</p><p>而在5.6以后，c字段也能下推判断，进一步的判断也减少了回表的记录数，加快了查询速度。</p></blockquote><h4><span id="索引联合">索引联合</span></h4><p>索引联合了解的不多，在使用or的等值查询过程中可能会用到索引联合，搜索两棵索引树在做值的整合，相当于 union all 吧。</p><blockquote><p>虽然索引有这好那好，但是走哪个索引还是依据优化器的，优化器也是根据抽样统计信息的，偶尔也可能出错。</p></blockquote><h3><span id="建立索引的思考">建立索引的思考</span></h3><ol><li>联合索引的字段排序（a，b，c 的联合索引，b 相对于 a 有序，c 相对于 b 有序，如果需要以a排序就可以建立（b，c，a 或者 c，b，a）索引，消除排序</li><li>字段的区分度（比如 sex，存它干嘛呢，撑死了三个值</li><li>实用程度（？，有些使用频率低的 SQL，可能并不需要特定的索引，索引也需要消耗一定的空间，并且降低更新和插入的效率。</li></ol><h2><span id="mysql-log日志">MySQL Log（日志</span></h2><p>MySQL 中存在多种日志，比如 <strong>binlog ，redo log 以及 undo log。</strong></p><p>redo log 和  undo log 属于 InnoDB 层的日志，而 binlog 属于 MySQL Server 层的日志。</p><p>binlog 主要用于主从复制，数据归档（可以单独根据 binlog 实现数据恢复，但不能保证 crash-safe</p><p>redo log 和 undo log 共同实现原子性，在正常的回滚下可能仅仅需要 undo log 来进行行记录的回滚，但是如果是经过 crash 则需要 redo log 来判断事务是否已经提交。</p><p>undo log 在 InnoDB 中另外实现了 MVCC。</p><h3><span id="binlog归档日志">binlog（归档日志</span></h3><p> binlog 属于归档日志，在 MySQL 中属于 Server 层日志， <strong>MySQL 中所有的存储引擎都会记录该日志。</strong></p><p>binlog  记录了所有的<strong>数据库变更操作</strong>，包括 UPDATE，INSERT，DELETE，也包括表结构的修改 ALTER TABLE 等。</p><p><strong>binlog 的主要作用是 1. 主从复制  2. 数据归档（奔溃后的适度恢复）。</strong></p><p>但是 binlog 并不能提供 crash-safe 的保证。</p><h4><span id="日志格式">日志格式</span></h4><p><strong>binlog 有如下三种格式：</strong></p><ol><li>statement</li></ol><p>statement 完整的保存执行的语句，但是因为 now() 等即时函数的存在复制的异常，所以用于复制的情况下会出现异常。</p><ol><li>row</li></ol><p><strong>row 记录的是表中数据 完整的变更，比如 now() 就会直接记录当前时间，数据较为准确，不会受语句上下文环境的影响</strong></p><p>但是相对的日志文件会比较大，因为 statement 一个删除语句，row 会保存所有的行记录。</p><ol><li>mixed</li></ol><p>mixed 基本上就是混合两种的情况。</p><h4><span id="相关配置">相关配置</span></h4><p>再说两个 binlog 相关的主要配置：</p><ol><li>binlog_cache_size</li></ol><p>该值表示在 MySQL 中 binlog 缓冲区的大小，用于缓存事务产生的 binlog。</p><p><strong>binlog cache 是线程私有的，不同线程之间不共享缓冲区。</strong></p><p>因为一个事务中可能涉及多个更新语句，并且多个更新语句不能拆分写入，因此需要单独一个缓冲区。</p><ol><li>sync_binlog</li></ol><p>binlog 的 fsync 刷盘策略，有如下几种配置形式：</p><ul><li>0 - 系统自由决定何时刷盘，所有 binlog 只做 write</li><li>1 - 每次都需要刷盘</li><li>n - 每次提交事务都会 write，但是n次的操作之后才会进行刷盘</li></ul><p>为0时性能最好，但是如果系统宕机，会丢失未落盘的内容。</p><h3><span id="redo-log重做日志">redo log（重做日志</span></h3><p>redo log 是 InnoDB 的日志，根据 Write Ahead Log（WAL）机制和 force log at commit 机制保证数据的持久性。</p><p>WAL（Write Ahead Log ）就是预写日志技术，在 InnoDB 中所有的修改都需要写日志，再做修改内存数据，同时在提交事务的时候也需要先将日志落盘。</p><p>所以理论上 redo log 可以单独提供 crash-safe 的保证。</p><p>redo log 中记录的是每次修改的物理日志，即每个数据页的修改（包含主键索引和次级索引。</p><h4><span id="redo-log-buffer">redo log buffer</span></h4><p>InnoDB 中的 redo log 有一个固定的大小的缓冲区，并且首尾相连组成一个环，环上有两个主要的指针: check_point 和 write_pos。</p><p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/16a7950217b3f0f4ed02db5db59562a7-7940422.png" alt="img"></p><p>在 write_pos 和 check_point 之间的就是日志的可写范围，如果刷盘不及时导致 write_pos 追上了 check_point，就会开启强制的刷盘（所以在 MySQL 大量写的时候会有瞬间抖动的现象。</p><p>另外在 MySQL 的后台线程也会定时刷盘，在正常关闭 MySQL 的时候也会将 redo log 落盘。</p><h4><span id="redo-log-的配置">redo log 的配置</span></h4><p>redo log 的刷盘策略也有参数控制 - <strong>innodb_fluish_log_at_trx_commit</strong>（这个非常非常重要！。</p><ol><li>innodb_fluish_log_at_trx_commit</li></ol><p>该参数为1时，每次的 redo log 都会调用 fsync，真正落盘持久化保存。</p><h3><span id="undo-log回滚日志">undo log（回滚日志</span></h3><p>undo log 在 InnoDB 中用于实现 MVCC 和原子性。</p><p>InnoDB 在修改行记录都会带有几个隐藏字段：</p><ol><li>TRX_ID -  修改的事务Id（事务 Id 由 MySQL 统一下发保证全局唯一并且递增。</li><li>ROLL_PTR - 回滚指针，指向旧版本数据，数据行根据指针组成一个单向链表（新 -&gt; 旧</li></ol><p><strong>MVCC 的实现就是在查询的时候沿着 ROLL_PTR 遍历到一个当前事务可见的行记录并返回（因此也存在 undo log 记录太多，导致查询缓慢的问题。</strong></p><p><strong>原子性的实现就是直接替换当前行记录，修改都是会上锁的所以不存在多个修改并行的情况。</strong></p><p>undo log 在 5.6 之后记录在单独的表空间，并且使用回滚段作为组织的形式。</p><blockquote><p>所以 undo log 并算不上 InnoDB WAL 机制的实现，因为 undo log 自身的持久化都要基于 redo log。</p></blockquote><p>undo log 不会一直存在，当事务提交的时候 undo log 就没有作用了（已经提交了，当前事务不需要回滚了），但是是否要删除还得看对于目前还存活的事务 undo log 是否可用。</p><p>最终的删除还是根据后台的 purge 线程决定。</p><h3><span id="binlog-和-redo-log-的-2pc二阶段提交">binlog 和 redo log 的 2PC（二阶段提交</span></h3><p><strong>binlog 和 redo log 需要做二阶段提交，保证双方日志的一致性，保证经过 binlog 复制的操作不会丢失或者被回滚。</strong></p><p>之所以要保证一致性的原因是因为 binlog 作为归档日志以及复制功能基础，如果 binlog 已经写入的数据，redo log 回滚，就会导致主从或者恢复前后的数据不一致。</p><p>二阶段提交的流程如下：</p><ol><li>准备阶段（Storage Engine（InnoDB） Transaction Prepare Phase）</li></ol><p>该阶段生成 XID（事务Id），进入 PREPARED 阶段，此时 binlog 不需要落盘，但 redo log 需要先落盘。</p><p>该阶段可能执行多次，每次修改都需要将 redo log 落盘。</p><ol><li>提交阶段（Storage Engine（InnoDB）Commit Phase）</li></ol><p>如果将事务提交，则将 binlog 落盘，如果回滚则使用 undo log 进行回滚。</p><ol><li>完成阶段</li></ol><p>事务提交或者回滚都需要看情况清除对应的 undo log。</p><p>binlog 在 2PC 中充当了事务的协调者（Transaction Coordinator），并且以 binlog 是否写入来判断事务是否成功，使用 XID 建立当前日志之间的对应关系。</p><p>在恢复的时候，redo log 检查到最近的 checkpoint，然后查看之后的日志，需要确定事务是否已经提交则通过 XID 找到对应的 binlog 俩判断 commit 状态。</p><h3><span id="group-commit组提交策略">group commit（组提交策略</span></h3><p><a href="https://www.modb.pro/db/62473">沙尘暴也阻挡不了学习的脚步– 面试官：你竟然不知道MySQL的组提交</a></p><h3><span id="checkpoint检查点">checkpoint（检查点</span></h3><p><strong>checkpoint 就是将脏页刷回磁盘的机制。</strong></p><p>当 MySQL 重启后会第一时间定位到最后的 checkpoint，在 checkpoint 之前的数据就不需要做恢复，只需要对其后的数据做恢复（按照 redo log。</p><p>checkpoint 可以分为以下两种：</p><ul><li>Sharp Checkpoint</li></ul><p>在当 MySQL 关闭的时候，需要将所有的脏页刷回磁盘，此时 checkpoint 会直接拉到日志最末尾。</p><ul><li>Fuzzy Checkpoint</li></ul><p>基本就是刷脏页的触发时机，包含后台定时线程触发，redo log buffer 里 write_point 追上 checkpoint 触发，LRU 空闲页面不够的刷盘。</p><h3><span id="lsnlog-sequence-number日志序列号">LSN（Log Sequence Number，日志序列号</span></h3><p>LSN 表示的就是日志的序号，在 InnoDB 中占8个字节。</p><p>表空间中的数据页、缓存页、内存中的 rodo log、磁盘中的 redo log 以及 checkponit 都有LSN标记。</p><h3><span id="崩溃恢复的流程">崩溃恢复的流程</span></h3><h3><span id="reference">reference</span></h3><ul><li><a href="https://huzb.me/2019/04/24/redo-undo%E5%92%8Cbinlog/">Redo log,Undo log 和 Binlog</a></li><li><a href="https://www.cnblogs.com/f-ck-need-u/p/9010872.html">详细分析MySQL事务日志(redo log和undo log)</a></li></ul><h2><span id="innodb-特性">InnoDB 特性</span></h2><h3><span id="一-change-buffer修改缓存">一、 Change Buffer（修改缓存</span></h3><p>Change Buffer 的主要作用就是<strong>缓存对二级（辅助）非唯一索引的修改</strong>（早期只在 Insert 操作中生效，称为 Insert Buffer。</p><p>Changer Buffer 属于日志的一种，在 InnoDB 底层的 Buffer Pool 中会占据一定的空间。</p><p>如果没有 Change Buffer，在一次数据更新中会需要将数据所有的索引树加载到 Buffer Pool 之后再做更新（因为 Redo Log 的存在，所以此时 Buffer Pool 不需要立即刷到磁盘中。</p><p><strong>Change Buffer 会在适当的时候进行 Merge</strong>，例如当索引页被加载到 Buffer Pool 的时候，或者服务空闲的时候，服务关闭之前等等。</p><p>Change Buffer 的机制可以和 redo log 做类比，redo log 减少了随机写的操作，而 Change Buffer 减少了随机读的操作（对于磁盘操作顺序操作比随机操作快了好几倍。</p><h3><span id="二-double-write两次写">二、Double Write（两次写</span></h3><p>InnoDB 的两次写是为了防止部分页刷新的问题。</p><p>默认的 InnoDB 内部的 Buffer Pool 的页大小为 16kb，但是系统写文件却大部分以 4kb 为单位，此时可能就出现页数据没有被完全写入就奔溃的情况。</p><p>MySQL 在磁盘共享空间中会创建一个 Double Write 的区域用于存放临时数据。</p><p>所有的脏数据写入会分为两次，一次写入 Double Write 的磁盘区，而后在将脏页具体刷盘。</p><h3><span id="三-flush-neighbor-page刷新邻接页">三、Flush Neighbor Page（刷新邻接页</span></h3><p>刷脏页的时候连带着将附近的一起刷了（处处透露着优化。</p><h3><span id="四-自适应-hash-索引">四、自适应 Hash 索引</span></h3><p>TODO</p><h3><span id="innodb-的内存管理lru">InnoDB 的内存管理（LRU</span></h3><p><strong>InnoDB 底层会申请一片的 Buffer Pool 用于保存数据页以及其他数据，默认情况下一页为 16kb（通过 innodb_page_size 控制。</strong></p><p>数据页会根据 LRU 算法进行保存，InnoDB 的 LRU 经过一定的优化，链表将其前 3&#x2F;8 的部分作为热数据区，后面的属于冷数据区，中间点可以称之为 midpoint。</p><p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/v2-b1542fa213b5322ed17364411af8cf99_1440w-7940422.jpg" alt="img"></p><p>读取的新数据并不是直接添加到链表的头部，而是添加到冷区头部，在一定的时间内被访问才会进入到热区。</p><p>再次基础上，LRU 还优化了热区的移动逻辑，热区前1&#x2F;4的数据被访问时不会再被移动（用来减少指针移动带来的锁。</p><p>此类优化适合数据库查询相结合的，因为部分查询可能会大量查询到无用的数据页（类似全表扫描），如果一股脑全部填充到首部会将真实的热数据冲散。</p><h4><span id="页分裂问题">页分裂问题</span></h4><p>InnoDB 中每张表都要求必须有一个主键Id（没有就隐式生成一个 row_id，并且主键索引就是聚簇索引，因此都是按照主键 Id 的顺序存放的数据。</p><p>当前主键 Id 递增时，每次都是在最后一页新增一行数据，如果超出则新申请一页，但当在两个主键中插入一个中间值时，此时如果页面数据也是满的就可能产生页分裂的情况。</p><p>页分裂的情况会导致部分数据需要被拷贝到新的数据页，因此也会显著降低插入的效率。</p><h2><span id="mysql-锁相关">MySQL 锁相关</span></h2><p>MySQL 中的锁需要根据存储引擎的不同来说。</p><p>在 MyISAM 中仅仅只有表锁，所有的插入操作都需要事先锁表，而 InnoDB 支持表锁，行锁，甚至多级上锁。</p><h3><span id="innodb-的基础锁类型">InnoDB 的基础锁类型</span></h3><p>InnoDB 中根据划分依据的不同存在多种不同的锁。</p><p>根据锁的粒度，或者说锁的目标来划分，存在以下几种锁：<strong>行锁，表锁，间隙锁。</strong></p><p>根据锁的排他性或者锁的目标行为来划分，存在<strong>写锁和读锁。</strong></p><h3><span id="二阶段锁协议">二阶段锁协议</span></h3><p><strong>二阶段锁协议的简单理解就是随机上锁，最终（事务提交）解锁。</strong></p><p><strong>在 InnoDB 中加锁的过程是根据语句的执行过程慢慢加的。</strong></p><blockquote><p>例如 <code>INSERT INTO ... SELECT ... FROM</code> 语句，该语句如果用于迁表，那么就会感觉到上锁的过程是跟随语句的执行过程慢慢发展到锁表。</p></blockquote><p><strong>而锁的释放是在事务提交之后一次性释放的。</strong></p><blockquote><p>中间可能会有一些优化，类似于 AUTO_INCREMENT 带来的插入锁，会提前释放，并且一些行锁也可能提前释放，但总得来说大部分的锁都还是在事务提交时被释放的。</p></blockquote><h3><span id="读锁和写锁">读锁和写锁</span></h3><p>读锁和写锁是锁的两个程度，读锁就是所谓的排他锁，而写锁就是所谓的共享锁。</p><blockquote><p>Javaer 可以直接联想 ReadWriteLock。</p></blockquote><p><strong>读锁和读锁之间相互兼容，写锁排斥一切。</strong></p><p>因为 MVCC 的存在，所以 MySQL 的查询一般来说是不会上锁的（因此，就算在写也是可以读到内容，并不是读写相融。</p><p>强行上锁可以使用以下语句加锁：</p><figure class="highlight lasso"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs lasso"><span class="hljs-comment">// 读锁</span><br><span class="hljs-keyword">SELECT</span> * FROM tableName <span class="hljs-keyword">WHERE</span> <span class="hljs-params">...</span> LOCK <span class="hljs-keyword">IN</span> SHARE MODE<br><span class="hljs-comment">// 写锁</span><br><span class="hljs-keyword">SELECT</span> * FROM tableName <span class="hljs-keyword">WHERE</span> <span class="hljs-params">...</span>  FOR UPDATE<br></code></pre></div></td></tr></table></figure><p>划分读锁和写锁的意义就在于，让两个读锁可以通知执行，增加并发度（基于 MVCC 的无锁化实现才是性能提升的最大原因。</p><h3><span id="行锁和表锁以及意向锁">行锁和表锁以及意向锁</span></h3><p>根据粒度划分，InnoDB 中存在行锁，也就是对<strong>表中的单行记录上锁</strong>，也有表锁，可以对<strong>整张表上锁</strong>。</p><blockquote><p>！！！InnoDB 中并没有真正意义上的表锁，就是直接对表上锁的那种，而是通过行锁+间隙锁的形式锁表。</p><p>多粒度的锁也是 InnoDB 的特性之一，MyISAM 就只有表锁。</p></blockquote><p><strong>对于常规的 CURD 语句，判断行锁还是表锁，简单来看就是是否走索引，不走索引的 CRUD 语句都会经过一个全表扫描的过程，扫描过程中慢慢的就会锁表。</strong></p><p>InnoDb 支持多粒度上锁，即表锁和行锁，如果表锁和行锁都为读锁，那也不会冲突，而如何在上表锁的时候判断是否在表中存在行锁就会出现问题，总不能扫表来判断是否有锁吧，此时就出现了意向锁。</p><p><strong>意向锁是为了兼容多粒度的锁而设计的</strong>，在上读锁的同时会给对应的表上读的意向锁，此时上写的表锁会被意向锁卡住。</p><h3><span id="gap-锁">GAP 锁</span></h3><p><strong>GAP 锁的锁定目标就是两个索引记录之间的区域（左开右闭）</strong>，GAP 锁的目的就是为了防止其他的事务在间隙（GAP）范围内插入数据。</p><p><strong>GAP 锁是共享锁</strong>，也就是说两个事务可以同时对相同的 GAP 上锁（咩有写的 GAP 锁。</p><p>GAP 锁仅仅在 RR 级别下生效。</p><h3><span id="next-key-lock">Next-Key Lock</span></h3><p>Next-Key Lock 就是<strong>行锁和 GAP 锁的结合</strong>，GAP 锁锁定的是命中的索引记录之前的间隙。</p><p>Next-Key Lock 的存在使 InnoDB 在 RR 级别下面就可以解决幻读问题。</p><h3><span id="死锁">死锁</span></h3><p>死锁出现的情况就是互相持有对象需要的锁。</p><blockquote><p>例如，持有A资源，等待B资源的线程和持有B资源，等待A资源的线程会造成死锁。</p></blockquote><p>死锁的必要条件：</p><ol><li>资源互斥 - 只有一个对象可以使用资源</li><li>占有等待 - 在等待另外的资源期间，已有资源并不会释放</li><li>不可强占 - 资源不可强行剥夺，即无法强行获取别的所持有的资源</li><li>循环等待 - 若干对象循环持有对方所需要的资源</li></ol><p>如何避免死锁（减少死锁的发生：</p><ol><li>缩小事务范围</li></ol><blockquote><p>MySQL 的上锁是逐步的，扫描索引树的时候逐步上锁，并且在事务提交的时候才会释放，所以缩小事务范围可以有效减少死锁的发生。</p><p>因为事务的解锁统一在事务的提交的时候，所以即使不同表的更新也会造成死锁。</p></blockquote><ol><li>尽量使用主键索引更新语句</li></ol><blockquote><p>避免对索引树的扫描导致一次更新覆盖太多的行。</p></blockquote><ol><li>以相同的顺序更新</li></ol><blockquote><p>死锁的原因是在更新多条记录的时候，互相持有部分记录的锁（单条记录的更新不会有死锁的问题。</p><p>所以将更新的顺序改为一致就可以解决死锁的问题，改死锁为等待（同个事务下更新的执行可以认为是无关先后顺序的，都是在提交的一刻生效。</p><p>对应的场景有 IM 中群聊会话的更新。</p></blockquote><h3><span id="rference">rference</span></h3><ul><li><a href="https://draveness.me/database-concurrency-control/">浅谈数据库并发控制 - 锁和 MVCC</a></li><li><a href="https://www.cnblogs.com/rjzheng/p/9950951.html">史上最全的select加锁分析(Mysql)</a></li></ul><h2><span id="排序算法">排序算法</span></h2><p>MySQL 中的排序算法包括三种：</p><ol><li>全字段排序</li></ol><p>全字段排序就是将全部需要的字段放入 sort_buffer 统一排序后返回。</p><ol><li>rowId 排序</li></ol><p>在排序内容较多的时候，可能仅使用 rowId + 排序字段进行排序，然后回表查询另外的内容。</p><p>此时的效率可能非常低，因为先根据筛选字段查询 rowId 以及 排序字段（此时可能已经经过一次回表，而排序结束之后可能再次使用 rowId 进行二次回表。</p><ol><li>索引树排序</li></ol><p>MySQL 索引本身就是有序的，因此如果排序条件满足索引（最左匹配原则，则可以直接使用索引中的顺序。</p><p>explain 的 Extra 字段中可能出现 filesort 标记，表示出现额外排序（并不一定是磁盘排序。</p><p>相关的还有分页问题，大数据量分页的时候可能会非常的慢，因为例如 limit 1000000,1000002; 此时会将 1000002 的数据全部先排序然后在选去后两条。</p><p>此时的优化应该减少待排序内容，使用索引或者子查询。</p><h2><span id="联表查询算法">联表查询算法</span></h2><p>联表查询包含如下几种形式：</p><ol><li>全连接&#x2F;内连接查询</li></ol><p>全链接查询最后的数据集只会保存驱动和被驱动表都匹配的数据。</p><p>例如 select * from a,b where a.id &#x3D; b.id。</p><p>此时 a 和 b 的 id 在对方表中无匹配项的就不会被返回。</p><ol><li>左连接查询</li><li>右连接查询</li></ol><blockquote><p>普通的 A join B，会是 MySQL 自行选择驱动表，而使用 A straight_join B，会固定 A 为驱动表。</p><p>驱动表可以简单理解为先查询的数据表，会根据驱动表的数据去匹配被驱动表。</p></blockquote><p><strong>联表查询的时候应该是小表作为驱动，小表的判断依据是单个表执行完 WHERE 语句之后剩余的数据集。</strong></p><h3><span id="index-nested-loop-join">Index Nested-Loop Join</span></h3><p>TODO</p><h3><span id="simple-nested-loop-join">Simple  Nested-Loop Join</span></h3><p>TODO</p><h3><span id="block-nested-loop-join">Block Nested-Loop Join</span></h3><p>TODO</p><h3><span id="相关参数">相关参数</span></h3><table><thead><tr><th align="center">参数名</th><th align="center">参数作用</th></tr></thead><tbody><tr><td align="center">join_buffer_size</td><td align="center">join buffer 的大小（在合适的范围之内，Join Buffer 肯定是越大越好</td></tr><tr><td align="center"></td><td align="center"></td></tr><tr><td align="center"></td><td align="center"></td></tr></tbody></table><h2><span id="分页算法">分页算法</span></h2><p>TODO</p><h2><span id="master-slave-replication主从复制">Master-Slave Replication（主从复制</span></h2><p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/a66c154c1bc51e071dd2cc8c1d6ca6a3-7940422.png" alt="img"></p><p>（还是 MySQL 45讲里面的图片。</p><h3><span id="复制的作用">复制的作用</span></h3><ol><li>多机备份，数据安全性保证（在单机突然爆炸的情况下也能保证数据安全</li><li>读性能的水平扩展（主从分离之后，可以将读写进一步分离</li><li>数据的异步化处理（例如阿里 canal，可以监听 binlog 用来进一步处理</li></ol><h3><span id="基本复制流程">基本复制流程</span></h3><p>MySQL 的主从复制是基于 Server 层的 binlog 实现的复制功能（可以类比于 Redis 的复制，binlog 转成 Redis 的复制缓冲区。</p><p>在 master 接收到 slave 传递的 start slave 指令后就开始复制过程，此时 slave 需要指定 binlog 的日志偏移量。</p><p>复制过程主要涉及的有以下几个线程（线程池）：</p><ol><li>Dump Thread</li></ol><p>master 侧的线程，负责从 binlog 中读取日志记录并推送到 Slave，注意读取的是 binlog 的磁盘文件（binlog 的缓存区是线程私有的也读取不到。</p><p>master 会为每个从节点创建一个 Dump Thread，从不同的起始点开始读取日志文件（因此一主多从多架构对主的要求很高。</p><ol><li>I&#x2F;O Thread</li></ol><p>slave 侧的线程，负责接收从 master 请求来的日志数据，并写入 relay log（relay log 就是中转日志，负责缓存从 master 接收的日志数据。</p><ol><li>SQL Thread Group</li></ol><p>旧版本的 MySQL 可能就是单个线程，在5.?之后变成了线程组，但是因为 SQL 语句可能存在上下文语境，因此并发执行需要额外判断。</p><p>该线程组用来执行从 relay log 解析出来的 SQL 语句。</p><p>和 Redis 不同的是，MySQL 支持 Master-Master（主主）架构，此时需要双方各自指定自身的 server_id 防止日志的无限复制。</p><p>另外的 MySQL 还支持级联复制，Slave 可以复制 Slave 节点的数据，主节点只需要创建一个 Dump Thread 去扩散日志，其他的从节点都从一级从节点复制。</p><h3><span id="replication-model复制模式">Replication Model（复制模式</span></h3><p>复制模式可以对比 Kafka 的 asks 参数策略，不同的模式反映了不同的一致性和安全性保证。</p><h4><span id="async-model异步模式">Async-Model（异步模式</span></h4><p>异步模式下，master 不会主动推送 binlog 到从节点，在接收到客户端的 SQL 以后，本地执行完毕就会返回结果，并不会关心从库是否已经接收。</p><p>该情况下，master 和 slave 可能存在明显的时间延迟，导致读写不一致，并且在 master 宕机之后如果以 slave 为新 master，可能出现数据丢失的情况。</p><h4><span id="semi-sync半同步模式">Semi-Sync（半同步模式</span></h4><p>半同步模式下，master 节点在执行完 SQL 之后会等待至少一个从库确定接收到对应 binlog 信息后才会返回结果。</p><p>此时写的性能至少延迟两个 TTL，并且写得性能完全看最快的节点。</p><h4><span id="sync全同步模式">Sync（全同步模式</span></h4><p>全同步模式则是进一步强化复制过程，需要全部的 slave 都已经复制 binlog 才会返回。</p><h3><span id="gtid-模式">GTID 模式</span></h3><p>GTID 模式是对复制进度的表示优化，之前的流程中 slave 需要指定 binlog 的复制偏移量来获取之后的日志，但是这个比较难以界定（鬼知道我最后一条日志在 binlog 的哪里），不仅难找而且容易遗漏，所以就出现了 GTID 模式。</p><p>GTID 就是 Global Transaction Identifier 即全局事务 Id，此时每个在主库上执行的事务都会指定一个唯一的 ID（全局递增，GTID 的组成由 server_id 和 transaction_id）。</p><p>GTID 模式下，通过 GTID 代替了之前的 binlog 偏移量，可以清楚的界定出复制的进度，在事务提交的过程中也会一起记录，在 SQL 线程回放的过程中也会对比本地的 binlog 判断是否已经执行保证 SQL 复制的幂等性。</p><h3><span id="reference">reference</span></h3><ul><li><a href="https://www.cnblogs.com/rickiyang/p/13856388.html">MySQL 主从复制原理不再难</a></li><li><a href="https://blog.nowcoder.net/n/b90c959437734a8583fddeaa6d102e43">【MySQL】主从复制实现原理详解</a></li></ul><h2><span id="explain-分析">Explain 分析</span></h2><blockquote><p>Explain 是 MySQL 中常规的 SQL 解析工具，能展示出SQL的部分执行逻辑和过程。</p><p>分析 Explain 的输出就能帮助我们优化和改进 SQL 语句。</p></blockquote><h3><span id="示例">示例</span></h3><figure class="highlight jboss-cli"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs jboss-cli">mysql&gt; explain select * from servers;<br>+<span class="hljs-params">----</span>+<span class="hljs-params">-------------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">---------------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">-------</span>+<br>| id | select_type | table   | type | possible_keys | key  | key_len | ref  | rows | Extra |<br>+<span class="hljs-params">----</span>+<span class="hljs-params">-------------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">---------------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">-------</span>+<br>|  1 | SIMPLE      | servers | ALL  | NULL          | NULL | NULL    | NULL |    1 | NULL  |<br>+<span class="hljs-params">----</span>+<span class="hljs-params">-------------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">---------------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">---------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">------</span>+<span class="hljs-params">-------</span>+<br>1 row in <span class="hljs-keyword">set</span> <span class="hljs-params">(0.03 sec)</span><br></code></pre></div></td></tr></table></figure><p>explain 用于展示 SQL 语句的执行计划，可以将其作为 SQL 优化的辅助工具。</p><p>主要关注的几个字段如下：</p><h3><span id="possible_keys">possible_keys</span></h3><p>可能选择索引名称。</p><p>这里会将表结构中可以用到的所有索引列出，然后从中选择效率最高的执行（可能选择错误）。</p><p>如果 possible_keys 为空，表示没有任何索引可以使用，所以都会作全表扫描处理。</p><h3><span id="key-x2f-key_len">key &#x2F; key_len</span></h3><p>最终选择的索引，以及索引的长度。</p><p>key_len 肯定是越小越好，类型上 int 的匹配优于字符串匹配。</p><h3><span id="rows">rows</span></h3><p>扫描行数。</p><p>每个查询语句可能扫描的记录行数，InnoDB 中该行数只是一个粗略值（经抽样统计得出）。</p><h3><span id="extra">extra</span></h3><p>额外信息，表示为了完成查询 MySQL 需要做的额外的事情（这里是不是指的 Server 层需要做的事情。</p><table><thead><tr><th align="center">额外信息</th><th align="center">出现含义</th><th align="center">如何解决</th></tr></thead><tbody><tr><td align="center">using where</td><td align="center">表示在 Server 层需要额外的判断</td><td align="center">一般来说不需要关心，不会太影响查询效率</td></tr><tr><td align="center">using index</td><td align="center">只需要读取索引文件就可以获取全部的数据，而不需要读取数据文件，表示不需要进行回表，或者直接使用索引覆盖。</td><td align="center">可</td></tr><tr><td align="center">using filesort</td><td align="center">需要进行额外排序（不一定包含文件排序</td><td align="center">可以利用联合索引的相对顺序避免排序</td></tr><tr><td align="center">using_index_condition</td><td align="center">使用了索引下推</td><td align="center"></td></tr><tr><td align="center"></td><td align="center"></td><td align="center"></td></tr></tbody></table><p><a href="https://dev.mysql.com/doc/refman/5.6/en/explain-output.html">MySQL - explain output format</a></p><h2><span id="q-amp-a">Q &amp; A</span></h2><h3><span id="innodb-和-myisam-的区别">InnoDB 和 MyISAM 的区别:</span></h3><table><thead><tr><th align="center">InnoDB</th><th align="center">MYSQL</th></tr></thead><tbody><tr><td align="center">支持事务</td><td align="center">不支持事务</td></tr><tr><td align="center">聚簇索引（主键索引就是聚簇索引，所以必须包含主键，没有就帮你隐式创建一个</td><td align="center">非聚簇索引（可以没有主键</td></tr><tr><td align="center">count 需要扫索引树（有 MVCC 也没法记准确的</td><td align="center">会在表中记录当前行数</td></tr><tr><td align="center">支持外键（虽然没啥卵用</td><td align="center">不支持外键</td></tr><tr><td align="center">多级锁机制（行锁，表锁，Gap 锁</td><td align="center">表锁（一个烂的摆</td></tr></tbody></table><h3><span id="如果解决深度分页问题">如果解决深度分页问题？</span></h3><h3><span id="索引失效的常见情况">索引失效的常见情况</span></h3><table><thead><tr><th align="center">索引失效的情况</th><th align="center">失效原因</th></tr></thead><tbody><tr><td align="center"><strong>索引列</strong>存在函数调用</td><td align="center">注意是对索引列的函数，对索引的函数操作可能会影响索引的有序性</td></tr><tr><td align="center">隐式的类型转换</td><td align="center">和上条类似，MySQL 中通常也是使用函数来进行类型转换（在 MySQL 中，字符串和数字做比较的话，是将字符串转换成数字。</td></tr><tr><td align="center">不满足最左前缀</td><td align="center">如果存在索引下推勉强能用</td></tr><tr><td align="center">左模糊匹配</td><td align="center">类似 LIKE %XX，对于字符串类型，索引的顺序是按照字典序排列的，因此左模糊匹配也会</td></tr></tbody></table><p>索引的原理就是按照有序性进行二分（一次性排除大量数据无用数据），所以在改变了有序性之后索引失效就是理所当然的。</p><h2><span id="reference">Reference</span></h2><ul><li><a href="https://dev.mysql.com/doc/refman/5.6/en/preface.html">官方文档</a></li></ul></bf>]]></content>
    
    
    <categories>
      
      <category>数据库</category>
      
    </categories>
    
    
    <tags>
      
      <tag>MySQL</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>TCP 协议（一</title>
    <link href="/2021/10/12/tcp%E5%8D%8F%E8%AE%AE%E6%95%B4%E7%90%86/"/>
    <url>/2021/10/12/tcp%E5%8D%8F%E8%AE%AE%E6%95%B4%E7%90%86/</url>
    
    <content type="html"><![CDATA[<h1><span id="tcp-协议一">TCP 协议（一</span></h1><ul><li>基于《TCP&#x2F;IP详解 卷一》和谢希仁《计算机网络（第6版）》的简单整理和总结。</li></ul><p>TCP是一种面向连接的，基于字节流的，可靠的传输控制协议。</p><p>属于OSI七层模型中的传输层。</p><h2><span id="内容梳理">内容梳理</span></h2><p><img src="/assets/TCP%E6%A8%A1%E5%9D%97%E6%95%B4%E7%90%86.png" alt="1569166769008"></p><ul><li>TCP的内容模块整理，方便记忆。</li></ul><h2><span id="一-tcp报文首部">一、TCP报文首部</span></h2><p><img src="/assets/TCP%E9%A6%96%E9%83%A8%E6%A0%BC%E5%BC%8F.png"></p><p>TCP首部大小在20~60字节，其中标准长度为20个字节。</p><p><strong>源端口和目的端口</strong></p><p>TCP的四元组为源IP，源端口，目的IP，目的端口，<strong>TCP首部中的源端口和目的端口结合IP首部中的源和目的IP地址组成了一个连接的四元组。</strong></p><p><strong>序号&#x2F;序列号(SEQ)</strong></p><p>在一个TCP连接中唯一标识TCP报文段，是重传机制的重要字段。</p><p>自ISN（初始序列号）起，单调递增。</p><p><strong>确认号(ACK)</strong></p><p>接收端发送给发送端，是期望对方下一个报文段的第一个字节的序号。</p><p><strong>值为N的ACK报文表示的是序号在N之前的报文全部已经收到，希望收到序号N的报文。</strong></p><p><strong>数据偏移</strong></p><p>表示TCP数据部分相对于整个TCP报文段来说的偏移量，可以简单理解为TCP首部的长度。</p><p><strong>控制位</strong></p><ol><li>URG - 紧急，置位后首部紧急指针生效</li><li>ACK - 确认，置位后确认号生效</li><li>PSH - 推送，置位后接收方应尽快给应用程序推送该段数据</li><li>RST - 重置，置位后表示该报文为重置报文，取消连接</li><li>SYN - 初始化，置位表示为初始化报文，用于初始化TCP连接</li><li>FIN - 结束，职位表示当前端结束数据传输工作</li></ol><p><strong>URG之前还有CWR - 拥塞窗口 以及 ECE - ECN回显，但是在一些TCP的实现里面并没有实现这两位。</strong></p><p><strong>窗口</strong></p><p><strong>通常在ACK报文中附带，作为接收方对发送方的背压，是影响发送端发送速率的因素之一。</strong></p><p>占16位，单位为字节，所以在没有<strong>窗口缩放</strong>选项的情况下，最大为65535字节。</p><p><strong>校验和</strong></p><p>报文段正确性校验使用占两位。</p><p>校验范围包括首部和数据部分，和UDP一样需要再生成12字节的伪首部参与计算。</p><p>伪首部包括源和目的IP，保证通信双方的正确性。</p><p><strong>紧急指针</strong></p><p>只有在<strong>URG控制位</strong>置位的情况下生效。</p><p>表示紧急报文在<strong>报文段序列号字段</strong>上的正偏移，序列号超过紧急指针的即为正常数据。</p><p>零窗口的情况下也可以发送紧急报文。</p><p><strong>选项</strong></p><p><strong>1. MSS - 最大报文段长度</strong></p><p>连接中每个TCP报文段的<strong>数据字段</strong>的最大长度，不包含首部。</p><p>在SYN报文中协商，双方都可以指定自己的MSS，甚至可以不同，默认为536字节。</p><p><strong>2. SACK - 选择确认</strong></p><p>当接收方接受到乱序数据时，就会在接收窗口产生缺口。</p><p>设置SACK选项就是为了描述这些缺口信息，使发送方更好，更准确的重传这些缺口数据。</p><p><strong>3. WSCALE&#x2F;WSOPT - 窗口缩放</strong></p><p>由于首部的<strong>窗口大小</strong>字段仅占16位，所以影响的范围也仅在0~2^16(65535)之间。</p><p>该选项就是为了增加窗口大小字段的范围，从16位提升至30位。</p><p>该选项只能出现在一个SYN报文段中，而SYN报文仅仅在初始化时通信双方各发一次，由此可知：</p><p><strong>连接建立之后窗口缩放的比例因子是与方向绑定的</strong>，通信双方的比例因子可以不同。</p><p><strong>4. TSOPT - 时间戳选项</strong> </p><p>该选项要求发送方在每一个报文中添加2个4字节的单调递增的时间戳数值。</p><p>分别是：<strong>TSval&#x2F;TSV 发送时间戳 以及 TSecr&#x2F;TSER 时间戳回显</strong>。</p><p>该选项的设置可以很好的解决重传的二义性，也能更加精确的计算RTT。</p><p><strong>5. 其他</strong></p><p>另外的还有<strong>认证选项</strong>以及<strong>用户超时选项</strong>等等。</p><h2><span id="二-连接管理">二、连接管理</span></h2><h3><span id="建立连接">建立连接</span></h3><p>稍微有点常识的程序猿应该都知道，TCP建立连接的时候需要往返发送三个报文。</p><p>   <img src="/assets/TCP%E6%89%93%E5%BC%80%E8%BF%9E%E6%8E%A5.png" alt="1568818645296"></p><p>连接发起者(客户端)会向服务端发送一个<strong>SYN报文</strong>，报文中除了目的端口，还包括ISN(初始序列号)以及部分选项字段。</p><p>服务端接受后会回复一个<strong>SYN报文</strong>作为响应，然后将接收到的SEQ+1，作为报文的ACK值，并指明服务端的的初始序列号等信息。</p><p>客户端响应一个ACK报文，同样的将服务端SYN报文中的SEQ+1作为ACK值。</p><h4><span id="为什么要三次握手">为什么要三次握手</span></h4><p>首先明确，<strong>三次握手的主要目的是交换双方的ISN以及选项。</strong></p><p>这些字段，例如是否启用SACK等都将是数据传输时的重要属性。</p><p>交换双方的信息至少需要两次握手，而第三次握手则是为了<strong>防止已失效的连接请求又被转发到了服务端</strong>。</p><p>意思就是如果客户端在收到服务端的SYN+ACK报文时就建立一个连接，那么在重传时将会出现先后多条连接的情况。</p><p>我感觉可能防止建立重复连接的功能可能是意外之喜。</p><p>另外<strong>可以发现SYN报文也占用了一个序列号。</strong></p><h3><span id="初始序列号-isn">初始序列号 - ISN</span></h3><p>在发送用于建立连接的SYN报文时，通信的双方都会选择一个初始化序列号。</p><p>每个连接都会有不同的初始化序列号。</p><p>《TCP&#x2F;IP详解》原文13.2章节:<strong>此外，为了确认客户端的SYN，服务器将其包含的ISN(c)数值加1后作为返回的ACK数值。因此，每发送一个SYN，序列号都会自动加1。这样如果出现丢失的情况，该SYN段将会重传</strong>。</p><p>wireshark测试下发现，客户端SYN报文的SEQ（也就是ISN）在重传时也不会改变。</p><h3><span id="关闭连接">关闭连接</span></h3><p>相对来说关闭连接的四次挥手就好理解多了。</p><p>   <img src="/assets/TCP%E5%85%B3%E9%97%AD%E8%BF%9E%E6%8E%A5.png" alt="1568820312811"></p><ol><li>连接的主动关闭方，发送一个FIN。</li><li>被动方回复一个ACK。</li><li>被动方主动发送一个FIN。</li><li>主动方回复一个ACK</li></ol><h4><span id="为什么要四次挥手">为什么要四次挥手</span></h4><p>和三次握手的区别，四次握手中被动关闭方的FIN报文和ACK拆开了，而三次握手的SYN报文和ACK是一起发出的。</p><p>至于为什么要拆开，我的理解是因为<strong>半关闭状态</strong>的存在，作为一个全双工的协议，连接的双方都可以互相发送数据。</p><p>半关闭状态是指TCP连接双方，有一端发送了FIN，而另一端还在继续传输数据，此时的主动关闭方仍然会对接收的数据作ACK的响应。 </p><p>一方发送了FIN报文就表示己方的数据发送完毕了，<strong>因此就分别需要两个FIN报文和两个ACK才足以完整的关闭一条(全双工)连接。</strong></p><h3><span id="同时打开和关闭">同时打开和关闭</span></h3><h4><span id="同时打开">同时打开</span></h4><p>通信双方在收到对方的SYN报文之前，都先发送了SYN报文，此时这种情况就叫做<strong>同时打开</strong>。</p><p>算是一种很少出现的特殊情况，但是TCP也能支持，并建立一条正常的连接。</p><div class="hljs code-wrapper"><pre><code>![](https://chenbxxx.oss-cn-beijing.aliyuncs.com/TCP同时打开.png)</code></pre></div><p><font size="1">我的画图软件不能支持斜线，只能靠盗图了</font></p><p>如图可见，通信的双方同时向对方发送一个SYN，并附带上自己的ISN(SEQ)。</p><p>接收方接受之后同样也同时作为被动发起方恢复一个ACK。</p><p><strong>此时通信双方即为客户端也为服务端，状态的变化一致，且回复的ACK中ISN与SYN中的一致。</strong></p><p>通信双方经历了相同的状态变更:<code>SYN_SENT</code> -&gt; <code>SYN_RCVD</code> -&gt; <code>ESTABLISHED</code></p><p><font size="2">我感觉TCP内部的实现中应该也是以SEQ作为参考依据。</font></p><h4><span id="同时关闭">同时关闭</span></h4><p>  <img src="/assets/TCP%E5%90%8C%E6%97%B6%E5%85%B3%E9%97%AD.png"></p><p>和同时打开差不多，<strong>同时关闭是在收到对方的FIN之前，向对方发送了自己的FIN报文。</strong></p><p>同样的通信双方经历了相同的状态变更:<code>FIN_WAIT_1</code> -&gt; <code>CLOSING</code> -&gt; <code>TIME_WAIT</code></p><p>可以看到双方是都需要等待一个2MSL的。</p><h3><span id="半打开半关闭半连接">半打开，半关闭，半连接</span></h3><p>以上是TCP连接中的三种特殊状态，就简单的叙述一下吧。</p><p>半连接是指<strong>服务端发送了SYN+ACK报文之后，等待客户端的ACK报文的这段时间</strong></p><p>半连接有类似的攻击手段:大量的请求发送到服务端但是永远不回复最后的ACK，导致服务端存在大量的半连接。</p><p>半打开是指<strong>如果一方已经关闭或异常终止连接，而另一方却不知道。</strong></p><p>半关闭上面也有提到过，<strong>通信的一方主动发送FIN之后表示本方不会再主动发送任何数据，但仍然可以接受对方的数据并响应的情况。</strong></p><h2><span id="三-tcp的有限状态机">三、TCP的有限状态机</span></h2><p><img src="/assets/TCP%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA.png"></p><p>上图即为《TCP&#x2F;IP详解 卷一》中的原图。</p><p>图中基本包含了全部的TCP连接状态变更，包括典型、非典型。</p><h3><span id="established">ESTABLISHED</span></h3><p><code>ESTABLISHED</code>状态是通信双方正常传输数据的状态。</p><p>作为三次握手的终点和四次挥手的起点。</p><h3><span id="time_wait状态">TIME_WAIT状态</span></h3><p><strong><code>TIME_WAIT</code>状态是主动关闭方在连接关闭的最后阶段必须经历的。</strong></p><p>在<strong>WAIT_TIME</strong>状态下，主动关闭方会判断本次的四元组不可用，所以此时就算对端重新请求SYN（接收到ACK释放连接之后），也会被拒绝。</p><p>进入该状态时，<strong>TCP会设置时间等待计时器(TIME_WAIT timer)，并等待2MSL的时间才会真正的释放连接，RFC793中建议为2min。</strong></p><p>MSL(Maximum Segment Lifetime)，也可以称为最大报文生存时间，<strong>是报文在所有链路中存在的最大时间，超过就会被丢弃。</strong></p><p>这么做的目的有以下两个：</p><ol><li>为了保证最后的ACK能够到达被动关闭方。</li></ol><p>从有限状态机的图中也可以看到，被动关闭方的连接真正释放是在收到最后一个ACK之后，所以必须要保证ACK的正确发送。</p><p><strong>等待2MSL能够有效避免最终的ACK丢失的情况，ACK不会主动重传，但是对端的FIN会重传直到收到正确的ACK为止。</strong></p><p>2MSL可以粗略的看做是己方ACK发送的时间加上对方FIN重传的时间。</p><p>当一个报连接处于<code>TIME_WAIT</code>状态时，任何延迟到达的报文都会被丢弃，只接收FIN报文。</p><p>另外<strong>TIME_WAIT</strong>的状态是从最后一个ACK发送开始，所以重新响应ACK之后，<strong>TIME_WAIT</strong>也会重新计时。</p><ol start="2"><li>保证相同四元组额前后连接报文不混淆</li></ol><p><strong>等待2MSL，就可以使本次连接的报文在链路中全部消失。</strong></p><p>期间TCP会将本次四元组定义为不可用，阻止重连。</p><p>如果不等待，相同四元组的连接如果重连，就有可能导致旧报文发送到新连接的情况，造成数据混乱。</p><p>2MSL是相对保守的处理方式，在ISN能超过上一次连接的最大序列号或者启用了时间戳选项的时候，感觉上可以跳过。</p><h3><span id="closing-状态">CLOSING 状态</span></h3><p><code>CLOSING</code>状态是TCP的非典型状态<font size="2">(一般情况下不会出现）</font>。</p><p>只有在上文提到过地<strong>同时关闭</strong>的情况下才会出现，同时关闭的通信双方在接收到对方的FIN，在发送ACK之后进入到<code>CLOSING</code>状态。</p><p>处于<code>CLOSING</code>状态下的通信双方在接收到对方的ACK之后，都会进入<code>TIME_WAIT</code>状态。</p><h2><span id="四-tcp的重传机制">四、TCP的重传机制</span></h2><p>TCP协议往下就是网络层的IP协议，但是IP协议并不提供任何可靠传输的服务，所以我们可以简单认为TCP所处链路都是不可靠的。</p><p>但是TCP介绍中也说了，它提供的是<strong>可靠的传输服务</strong>，因此也就要求TCP协议自身来补足IP协议中的不可靠部分。</p><h3><span id="可靠传输的基础">可靠传输的基础</span></h3><p><strong>TCP的重传机制是基于<code>连续ARQ协议</code>实现的。</strong></p><p>维基百科对<code>ARQ</code>的解释如下：</p><blockquote><p>ARQ协议，即自动重传请求（Automatic Repeat-reQuest），是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超时这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送后一段时间之内没有收到确认帧，它通常会重新发送。</p></blockquote><h4><span id="停止等待arq协议">停止等待ARQ协议</span></h4><p> <img src="/assets/%E5%81%9C%E6%AD%A2%E7%AD%89%E5%BE%85ARQ.png"></p><p><strong>一个分组一个分组的发送，在收到确认之前不会发送下一个分组，如果出现超时就重传丢失分组。</strong></p><p>该协议能够完全保证通信的可靠新，但是显而易见的<strong>该协议的利用率很成问题</strong>，在发送完一个分组到确认到达的这段时间信道都是空闲的。</p><p>即使整个链路十分可靠，依旧要等待确认信息的到达。</p><p>而且判断分组是否丢失的算法就是<strong>在一定时间内，是否收到接受的确认信息</strong>，过于粗暴很容易出现伪重传的情况。</p><h4><span id="连续arq协议">连续ARQ协议</span></h4><p><code>连续ARQ协议</code>可以说是对<code>停止等待ARQ协议</code>的优化。</p><p><strong>在停止等待ARQ协议之上，每次发送多个报文，并等待这些分组的确认信息</strong></p><p> <img src="/assets/%E8%BF%9E%E7%BB%ADARQ.png"></p><p>连续ARQ协议虽然提高了信道利用率，但是仍然会存在<strong>回退N</strong>等问题。</p><h3><span id="确认机制">确认机制</span></h3><p><strong>确认机制指的就是接收端在收到一个正确的报文时，会给发送端回传一个ACK，表明报文已经到达。</strong></p><h4><span id="延迟确认x2f累计确认机制">延迟确认&#x2F;累计确认机制</span></h4><p><strong>接收端在收到数据之后，并不会立马回传ACK，而是会延迟一定的时间(延迟确认)，发送的时候会以最大有序报文的序号作为ACK的数值(累计确认)。</strong></p><p>这样的目的很明确就是<strong>减少ACK报文的数量，降低ACK造成的网络负担</strong>。</p><h4><span id="选择确认sack">选择确认SACK</span></h4><p>选择确认是TCP首部中的选项，启用SACK功能需要通信双方事先确认，之前也说过SACK字段是为了<strong>描述接收端的接收缺口，帮助发送方更加准确的重传丢失报文。</strong></p><p>可以在一个ACK报文中，指明多个缺口信息(最多三个)，普通的ACK报文可以看做是单个的缺口信息。</p><h3><span id="超时重传">超时重传</span></h3><p><strong>超时重传又可以称为基于计时器的重传。</strong></p><p>TCP每发送一个报文，都会设定一个<strong>重传计时器</strong>，若在计时器超时时都没有收到确认消息，就会触发重传操作。</p><p>超时重传的整体逻辑并不复杂，但是<strong>超时时间的选择</strong>却是TCP最难的问题之一。</p><p>简单超时时间设置，比如SYN的重传 - <strong>每次SYN重传的超时时间都是上一次的简单加倍</strong>，比如说上次过了2s之后重传报文，这次就应该等待4s或者6s，这种方式称为<strong>二进制指数退避</strong>。</p><p>复杂一点的设置就会根据报文的RTT推算RTO。</p><blockquote><p>RTT （报文段往返时间）- 从报文发出到接受到该报文的ACK所花费的总时间。</p><p>RTO （超时重传时间）- 从报文发出到重传报文所花费的时间，也就是所谓的重传超时时间。</p></blockquote><p><font size="1">这里并不是很懂，就先空着了</font></p><h3><span id="快速重传">快速重传</span></h3><p>快速重传是基于接收端反馈信息的重传模式。</p><p><strong>首先在TCP中，接收方如果收到一个失序的报文段就会立即发送重复的ACK，而不会选择延迟或者累积。</strong></p><p>因此如果接收端的接收缓存中出现缺口，那么后续到达的报文就会 重复确认同一个报文。</p><p>简单的举个例子：</p><p>接收端的缓存中存在的是报文1,2,3,4，且还未发送ACK，如果此时报文6到达，那么接收端就会立马发送一个ACK&#x3D;5的报文，如果报文5一直没有到达，那么在报文7,8,9到达时，都会发送一个ACK&#x3D;5的重复确认报文。</p><p><strong>发送方接收到的重复确认报文达到一定阈值(通常为3)之后，就会立马重传确认报文中指定缺失的报文。</strong></p><p>快速重传同时也是拥塞控制中的重要算法。</p><h3><span id="伪重传的判定和响应">伪重传的判定和响应</span></h3><p>伪重传就是指在没有发生数据丢失时，但仍然进行了重传的情况。</p><p>导致伪重传的原因有超时时间误差，包失序，包重复或者ACK丢失等。</p><p>判定是否是伪重传的方法有以下集中：</p><ol><li><p><strong>DSACK 重复的SACK</strong></p><p>对SACK的增强，<strong>可以在第一次SACK块中可以指明接收端中重复收到的报文端序列号。</strong></p></li><li><p><strong>Eifel检测算法</strong></p><p>该算法需要首部中的时间戳选项支持。</p><p>TCP会在重传的的时候记录下重传报文的TSV，当接收到重传报文是会对比回显TSER和保存的TSV对比。</p><p>如果TSER &lt; TSV，则表示是伪重传。</p></li></ol><p>DSACK只能在接收到重传的ACK之后才能判断此次是否是伪重传，而Eifel检测算法是在第一个ACK到达时，就能判断出来，可能此时重传报文都还没传输到接收端。</p><h3><span id="重复-失序以及重新组包">重复、失序以及重新组包</span></h3><h4><span id="失序">失序</span></h4><p>包失序可能由IP协议或者链路状态引起，因为IP协议不能保证包的有序发送，而且就算是有序发送但是在动态的网络中也不能保证包有序的到达接收端。</p><p>上文也有提到过，当接收到一个失序的报文时，接收端会立马响应一个ACK。</p><p>少量的失序并不会造成什么影响，但如果失序报文间隔的报文数目超过快速重传的阈值，就会触发重传，还是伪重传。</p><h4><span id="重复">重复</span></h4><p>《TCP&#x2F;IP详解 卷一》中也说了IP协议可能出现单次包传输多次的情况，因此也就产生了重复问题。</p><p>重复次数过多也就会触发重传。</p><h4><span id="重新组包">重新组包</span></h4><p>当TCP重传报文时，它并不需要完全重传相同的报文，为了提高性能等原因，可能会发送更大的包。</p><h2><span id="五-窗口管理">五、窗口管理</span></h2><p>TCP协议中采用滑动窗口机制来实现流量控制。<font size="1">(所以窗口管理也是流量控制的关键)</font></p><p><strong>接受端和发送端各自都会维护一个发送窗口结构和一个接受窗口结构。</strong></p><p>窗口结构以字节为单位</p><p>上文也说过TCP首部中窗口字段，是接收端回传给发送端的，并以此作为背压控制发送方的发送窗口大小，这也被称作<strong>通告窗口</strong>。</p><h3><span id="tcp的流量控制">TCP的流量控制</span></h3><p>因为TCP的流量控制基本是上基于窗口实现的，所以这块内容我也放到这里了。</p><p><strong>流量控制的的主要目的就是在保持相对较高的传输速率的同时，还要保障收发速度平衡。</strong></p><p>TCP的流量控制机制就是<strong>通过调节ACK数据包中的窗口大小字段实现的</strong>，这种方法在控制发送方速率的同时，也明确了接收方的缓存信息，防止接收方的缓存溢出。</p><h3><span id="发送端窗口结构">发送端窗口结构</span></h3><p> <img src="/home/chen/.config/Typora/typora-user-images/1569251203979.png" alt="1569251203979"></p><p>上图即为发送端的窗口结构。</p><p>中间的发送窗口即为活动窗口，TCP会按照顺序发送区间内的报文。</p><p>当接收到返回的数据ACK时，活动窗口也随之右移动，左右两边的相对运动就控制着窗口的大小。</p><p>窗口的活动有图中三种：</p><ol><li><p>关闭（close）-  活动窗口左边界右移，<strong>当收到ACK数据时会进行此操作，使窗口减小。</strong></p></li><li><p>打开（open）-  活动窗口的右边界右移，<strong>当接收的报文被处理时会触发此操作，使窗口增大。</strong></p><p>程序也需要TCP报文中的窗口大小字段判断窗口具体增大多少。</p></li><li><p>收缩（shrink）-  活动窗口的右边界左移动，使窗口减小，<strong>TCP的协议中强烈不建议此操作。</strong></p></li></ol><p><strong>窗口的左边界明确说明不能左移,因为它代表的是已经被确认的数据</strong></p><h3><span id="接收端窗口结构">接收端窗口结构</span></h3><p> <img src="/home/chen/.config/Typora/typora-user-images/1569252451692.png" alt="1569252451692"></p><p>对比于发送端，接收端的窗口结构简单很多，<strong>对于活动窗口(接收窗口)内部并不进行细分</strong>。</p><p>如果到达的报文在<strong>接受已确认或者无法接受</strong>范围，则会被丢弃。</p><p>在接受窗口范围内会被缓存，只有在最左边的数据接收到之后整个窗口才能右移。</p><p>同样的接受窗口的左边界不能左移。</p><h3><span id="零窗口问题">零窗口问题</span></h3><p>当持续收到ACK，但是应用程序并没有及时处理收到的数据(持续关闭，未打开)时，如果左右边界重合，就会出现所谓的<strong>零窗口</strong>现象。</p><p><strong>在接收端窗口扩大重新获得可用窗口空间时，会给发送端发送一个窗口更新报文(window update)，通知其可以继续发送数据。</strong></p><p><strong>送端也会采用一个持续计时器的机制，当计时器超时就会发送窗口探测报文(window probe)，强制要求接收端响应一个ACK报文(首部中包含窗口大小字段)。</strong></p><h3><span id="nagle算法">Nagle算法</span></h3><p><strong>Nagle算法通过减少包发送量来增加网络传输的效率。</strong></p><p><strong>小数据包问题</strong>  -  即TCP数据包中有效负载较低的问题，一个数据包中至少20字节的TCP首部以及20字节的IP首部，而真实数据甚至可能只有1字节，这就是很严重的浪费。</p><p>Nagle算法规定：<strong>TCP连接中任意时刻都只能存在一个未经确认的小包，此时不能发送长度小于MSS的包，直到所有数据都ACK之后再合并（coalescing）所有待发送的数据包发送。</strong></p><p>Nagle算法的规则（可参考tcp_output.c文件里tcp_nagle_check函数注释）：</p><p>（1）如果包长度达到MSS，则允许发送；</p><p>（2）如果该包含有FIN，则允许发送；</p><p>（3）设置了TCP_NODELAY选项，则允许发送；</p><p>（4）未设置TCP_CORK选项时，若所有发出去的小数据包（包长度小于MSS）均被确认，则允许发送；</p><p>（5）上述条件都未满足，但发生了超时（一般为200ms），则立即发送。</p><p><font size="1">这段照抄的…</font></p><p>Nagle算法同时迫使TCP遵循了停止-等待协议，或者说扩展了停止-等待协议。</p><p>网络良好的情况下，如果ACK回复的很快，发送端缓存也并没有积累多少数据，此时Nagle算法反而会使整体的传输时间更长。</p><h3><span id="糊涂窗口综合症silly-window-syndrome">糊涂窗口综合症（<strong>Silly window syndrome</strong>）</span></h3><p> 维基百科百科中对<a href="https://w.wikipedia.org/wiki/%E7%B3%8A%E6%B6%82%E7%AA%97%E5%8F%A3%E7%BB%BC%E5%90%88%E7%97%87">糊涂窗口综合症</a>的说明如下：</p><blockquote><p><strong>糊涂窗口综合症</strong>（<strong>Silly window syndrome</strong>），亦称<strong>愚蠢窗口综合症</strong>、<strong>愚笨窗口综合症</strong>，是<a href="https://zh.wikipedia.org/wiki/%E4%BC%A0%E8%BE%93%E6%8E%A7%E5%88%B6%E5%8D%8F%E8%AE%AE">TCP</a><a href="https://zh.wikipedia.org/w/index.php?title=Flow_control_(data)&action=edit&redlink=1">流量控制</a>实现不良导致的一种<a href="https://zh.wikipedia.org/wiki/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C">计算机网络</a>问题。当发送程序缓慢地创建数据，接收程序缓慢地消耗数据，或者两者同时存在时，滑动窗口运作会出现严重问题。</p></blockquote><p><strong>严重问题</strong>就是指的小数据包问题。</p><p>举个例子：</p><p>若接收端的应用程序处理数据很慢，且每次只处理1个字节的数据，那么接受端的缓存慢慢积累之后就会出现零窗口情况，而处理完1个字节之后缓存有多出了一个字节，此时如果服务端发送窗口更新报文，告诉发送端你只能发送1个字节数据的报文，可想而知效率会有多低。</p><p>导致SWS出现的情况有以下几种：</p><ol><li>接收端通告窗口较小</li><li>发送端发送的数据段较小</li></ol><p>两端都有可能造成SWS，所以也需要同时从两端解决问题，发送端不应该发送小的报文段<font size="1">(此时Nagle算法可以帮助发送端解决部分发送端的问题)</font>，而接收端不应该通告小的窗口。</p><p>根据以上情况具体的规则应该按照发送端和接收端区分，</p><p><strong>针对发送端而言应该交由Nagle算法控制发送的时间</strong>，而且只有满足以下条件，报文才能被传输：</p><ol><li>长度为MSS的报文可以被传输。</li><li>报文长度大于接收端最大窗口值的一半可以发送</li><li>某一ACK不是目前期盼的(重传?)</li><li>连接禁用了Nagle算法</li></ol><p><strong>针对于接收端来说，不应该通告小的窗口值，在窗口增长至一个全长的报文段(MSS)或者接收端缓存空间的一半之前，不能通告该窗口。</strong></p><h2><span id="六-tcp拥塞控制">六、TCP拥塞控制</span></h2><ul><li>《TCP&#x2F;IP详解》里该段内容太复杂了，大概的瞥了眼内容，详细的等我以后有空再看吧 。</li></ul><p><strong>拥塞控制的目的就是为了防止过多的包进入链路中，导致链路中的路由器等设备过载而丢弃数据包，引发拥塞。</strong></p><p>TCP协议中，由<strong>发送方维护</strong>一个反映网络传输能力的的变量叫做<strong>拥塞窗口</strong>(cwnd)，所以<strong>发送端的活动窗口实际值为拥塞窗口和通告窗口的较小值。</strong></p><p>拥塞窗口同时</p><p>因为拥塞控制是一个全局性的过程，网络传输能力也不仅仅取决于收发端，所以cwnd也无法取到一个准备的值，只能靠一步步的推测。</p><h3><span id="慢开始">慢开始</span></h3><p>慢开始的目的<strong>是在不清楚网络传输能力的情况下，以少量包慢慢递增的形式进行探测。</strong></p><p><strong>拥塞窗口大小在每次接收到一个正确的ACK时+1</strong>，所以拥塞窗口大小整体呈指数形式递增。</p><p>假设起始的拥塞窗口为n，在每接收到一个ACK之后拥塞窗口加1，所以如果网络良好ACK全部按时收到，那么在第一个RTT时间内拥塞窗口就变为了2n，之后便是4n，以指数增长。</p><p><strong>另外由于接收端的延迟确认机制，所以并不会完全按照指数增长。</strong></p><p><strong>慢开始的慢并不是增长速度慢，而是初始的拥塞窗口小</strong>，在不清楚网络传输能力的情况下，并不会一下子就设置太大的拥塞窗口。</p><p>慢开始的触发条件有以下几个：</p><ol><li>TCP连接刚初始化</li><li>检测到超时重传(丢包)</li><li>长时间处于空闲状态的连接</li></ol><p>另外慢开始还会预先设置一个慢开始门限(ssthresh)：</p><ol><li>当cwnd &lt; ssthresh时，执行慢开始算法</li><li>当cwnd &gt; ssthresh时，改用拥塞避免算法</li><li>当cwnd &#x3D; ssthresh时，慢开始和拥塞避免都可以</li></ol><p>慢开始门限并不是固定的，而是会随着时间变化，它代表的是TCP对最佳窗口大小的估计值。</p><p><strong>慢启动状态下，TCP判断是否发生拥塞的依据就是是否有丢包。</strong></p><h3><span id="拥塞避免">拥塞避免</span></h3><p><strong>拥塞避免的作用就是让cwnd缓慢的线性增长。</strong></p><p>虽然是慢开始，但是指数增长的速度过于快速，所以在达到阈值之后会改用拥塞避免。</p><p><strong>慢开始和拥塞避免最大的区别就在于ACK到达之后cwnd如何变化。</strong></p><p>不论是在慢开始还是用三个避免阶段，只要出现重传的情况(重传就表示TCP判定出现丢包)，TCP就会认为此时的cwnd超出网络传输能力，此时会将慢启动门限(ssthresh)减半。</p><h3><span id="快恢复">快恢复</span></h3><p><strong>快恢复</strong>（Fast recovery）是Reno算法新引入的一个阶段，在将丢失的分段重传后，启动一个超时定时器，并等待该丢失分段包的分段确认后，再进入拥塞控制阶段。如果仍然超时，则回到慢启动阶段。</p><p>快恢复算法需要<strong>快重传</strong>配合，在接收到三个连续的ACK(触发快速重传时)，快恢复算法会执行如下流程：</p><ol><li>慢开始门限减半(ssthresh&#x2F;2)</li><li>执行快重传算法，设置拥塞窗口(cwnd)为减半门限(ssthresh&#x2F;2) + 3MSS(也有不加的TCP实现)</li><li>每接受到一个重复ACK报文，拥塞窗口(cwnd)临时+1</li><li>接收到正确的ACK报文时，cwnd被设置到减半门限(ssthresh&#x2F;2)</li></ol><p>拥塞控制的流程图：</p><p>  <img src="/assets/%E6%8B%A5%E5%A1%9E%E6%8E%A7%E5%88%B6.jpg" alt="img"></p><h3><span id="tcp-reno和tcp-tahoe">TCP Reno和TCP Tahoe</span></h3><p>TCP Reno和TCP Tahoe是两种不同的拥塞控制算法。</p><p><strong>两种算法对于拥塞的判断都是根据重传超时或者重复确认。</strong></p><p>如果发生重传超时两种算法的处理逻辑一致，都会将拥塞窗口设置为1MSS，然后重新开始慢开始算法。</p><p>但是对于重复确认来说两种算法不同：</p><p>Tahoe算法在收到超过阈值的重复ACK之后先触发的快速重传算法，<strong>将慢开始门限设置为当前拥塞窗口(cwnd)的一半，拥塞窗口变为1MSS，再重新开始慢开始算法。</strong></p><p>Reno不同的在于快速重传之后的处理，首先慢开始门限是减半，变为当前慢开始门限的一半+3MSS，而且跳过慢开始阶段，直接以减半的慢开始门限作为拥塞窗口(cwnd)，直接跑拥塞避免。</p>]]></content>
    
    
    <categories>
      
      <category>网络</category>
      
    </categories>
    
    
    <tags>
      
      <tag>tcp</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>synchronized 相关内容整理</title>
    <link href="/2021/07/15/Synchronized/"/>
    <url>/2021/07/15/Synchronized/</url>
    
    <content type="html"><![CDATA[<h2><span id="知识脑图">知识脑图</span></h2><p><img src="/assets/image-20210715211623026.png" alt="Synchronized 脑图"></p><h2><span id="概述">概述</span></h2><p>synchronized 是 Java 提供的同步原语，背后是 Java虚拟机(JVM) 提供的 Monitor 机制。</p><blockquote><p>Java 中任何一个对象都可以作为监视器 (Monitor) 对象，因为 Monitor 是通过 C++ 实现的对于 Object 类的扩展机制，该对象保存了锁相关的数据结构，例如保存阻塞线程列表等。</p></blockquote><p>synchronized 修饰的代码块只能由单个线程执行，以互斥锁的形式保证了其线程安全。</p><p><strong>synchronized 具有可重入性，单线程可以重复对一个对象上锁，而不会自我阻塞，但解锁还是一次性的。</strong></p><p><strong>synchronized 保证了程序的可见性和原子性以及有序性。<font size="2">(volatile只能保证可见性以及有序性，而无原子性)</font></strong></p><p><strong>synchronized 不具备公平性，会导致饥饿，而使线程阻塞时间过长。</strong></p><blockquote><p>饥饿就是指线程因为获取不到想要的资源而长时间不能执行。</p></blockquote><p>另外和 synchronized 搭配使用的还有 wait()&#x2F;notify()&#x2F;notifyAll() 三个方法。</p><br><br><h2><span id="synchronized的锁形式">synchronized的锁形式</span></h2><p><code>synchronized </code>有三种上锁形式，分别会对不同的对象上锁:</p><ol><li><p>修饰实例方法</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// 此时的上锁对象为当前的实例</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">syncMethod</span><span class="hljs-params">()</span>&#123;&#125;;<br></code></pre></div></td></tr></table></figure></li><li><p>修饰代码块</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">syncMethod</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-comment">// 此时上锁为lock对象.也可为Class对象 eg: lock.class</span><br>    <span class="hljs-keyword">synchronized</span>(lock)&#123;&#125;<br>&#125;<br></code></pre></div></td></tr></table></figure></li><li><p>修饰静态方法</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// 此时的上锁对象为Class对象</span><br><span class="hljs-keyword">public</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">synchronized</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">syncMethod</span><span class="hljs-params">()</span>&#123;&#125;;<br></code></pre></div></td></tr></table></figure></li></ol><br><br><h2><span id="synchronized的虚拟机层实现">synchronized的虚拟机层实现</span></h2><p>synchronized 根据不同的上锁形式会有不同的实现方式。</p><ol><li><p>在修饰代码块时使用的是明确的 <strong>monitorenter 和 monitorexit</strong> 两个指令</p><p> <img src="/assets/javap_moitorenter_exit-7942538.png" alt="javap_moitorenter_exit"></p><blockquote><p>退出实际上是两次的，在方法执行完毕之后还会执行一次 monitorexit</p></blockquote> <br></li><li><p>在修饰方法(包括静态方法)时由方法调用指令读取运行时常量池方法中的  <strong>ACC_SYNCHRONIZED</strong> 隐式实现</p><p>   <img src="/assets/javap_acc_synchronized-7942540.jpg" alt="javap_acc_synchronized"></p></li></ol><br><br><h2><span id="mark-word">Mark Word</span></h2><p>Mark Word  是  Java对象头 结构中除类型指针外的另一部分，用于记录  HashCode ，对象的年龄分代，锁状态标志等运行时数据。</p><blockquote><p>Java 的对象头包含了 <strong>Mark Word，类型指针和对齐填充。</strong></p></blockquote><p>下图中就比较清晰的展示了，不同情况下 Mark Word 的不同结构：</p><p><img src="/assets/markword-7942543.jpg" alt="markword"></p><blockquote><p>Mark Word 相当于是锁的记录，查看 Mark Word 就可以确定当前 Monitor 锁的状态。<br></p></blockquote><br><h2><span id="monitor-监视器管程">Monitor 监视器(管程)</span></h2><p>Monitor 是虚拟机内建的用来实现同步的机制，原则上Java的每一个对象都可以作为 Monitor。</p><blockquote><p><code>Monitor</code>的实现还是依赖于操作系统的<code>Mutex Lock</code>(互斥锁)来实现的，对于操作系统层面的实现不深究。</p><p>因为线程的阻塞，恢复以及 mutex 的调用等都涉及到用户态到内核态的切换，所以性能有限。</p></blockquote><p><img src="/assets/JVM_Monitor-7942546.jpeg" alt="JVM_Monitor"></p><p>上图可以简单说明整个 Monitor 机制的工作方法。</p><p>Entry Set 存放所有竞争线程集合，Wait Set 存放所有的等待线程的集合。</p><blockquote><p>都是用 Set 表示了，所以 synchronized 并不是公平锁，存在饥饿的情况。</p></blockquote><p>进入同步代码块的时候，线程先加入到 Entry Set，如果获取到锁则变为 Owner，期间调用了 wait() 方法后，进入 Wait Set，调用了 notify() 之后回到 Entry Set 继续竞争锁资源，代码块执行完毕则会退出。</p><p>只有 Owner 代表的线程才可以执行标识的代码块，也就保证了锁的互斥性。</p><blockquote><p>Monitor 是以 C++ 实现的，虚拟机内建的互斥锁机制，Java中还可以使用 ReentrantLock 和 Condition 对象实现更加灵活的控制。</p><p>Condition 中也有 await()&#x2F;signal()&#x2F;signalAll() 等配套方法。</p></blockquote><br><br><h2><span id="waitx2fnotifyx2fnotifyall">wait()&#x2F;notify()&#x2F;notifyAll()</span></h2><blockquote><p><strong>以上三个方法都需要在获取到 Monitor 锁的状态下执行，也就是说在 synchronized 代码块中执行。</strong></p></blockquote><p>以上三个方法都在 Object 类中声明。</p><blockquote><p>Class 对象也继承与 Object 对象，所以 Class 对象也能作为 Monitor 锁对象。</p></blockquote><p>wait() 会释放当前的 Monitor 锁，并使线程进入 WAITING 或者 TIMED_WAITING 状态，在上图中就是进入到 Wait Set 中，另外 wait(long) 可以指定超时时间。 </p><p>notify() 会从当前的 Monitor 的 Wait Set 中唤醒一个等待的线程，notifyAll() 则是唤醒全部的线程。</p><blockquote><p>notify() 唤醒的线程会进入到 Entry Set，而不是直接获取到锁，当前线程也不会直接释放锁。</p><p>所以如果通过 wait() 阻塞的线程重新执行时候需要重新判断执行条件。</p></blockquote><br><br><h2><span id="synchronized的优化hotspot">synchronized的优化<font size="2">(HotSpot)</font></span></h2><p>JDK1.6  之前  synchronized  一直为重量级锁，直接使用互斥锁阻塞线程，也就导致了一定的性能问题。</p><blockquote><p>性能问题主要来源于线程状态的切换，以及用户态和内核态之间的来回切换。</p></blockquote><p>HopSpot  在  JDK1.6 之后加入了<strong>偏向锁，自旋锁，自适应自旋锁，轻量级锁等优化</strong>.</p><p>锁级别从低到高依次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，<strong>绝大多数情况下，锁可以升级但不能降级。</strong></p><br><h3><span id="锁的转换关系">锁的转换关系</span></h3><p><img src="/assets/java_synchronized-7942549.jpg" alt="synchronizd 的锁转换"></p><ul><li>我觉得上图已经很好的展示了几个状态之间的转化，就不在赘述了.<font size="1">(估计也讲不好)</font></li></ul><br><h4><span id="偏向锁相关问题">偏向锁相关问题</span></h4><p>和群友讨论的时候发现的问题:<strong>如果使用了偏向锁，那么势必会占据 MarkWord 中 HashCode 的位置，那么此时的 HashCode 又保存在哪里？</strong></p><p>在以下的文章中看的了答案，简单来说就是:</p><ul><li>HashCode 和偏向线程Id并不会共存，且 HashCode 的优先级高于偏向线程ID</li><li>如果处于偏向锁时，计算了 HashCode，那么锁会直接膨胀为重量级锁或者轻量级锁。</li><li>如果存在 HashCode ， MarkWord 即为不可偏向状态。</li><li>因为轻量级锁会将 Mark Word 复制到虚拟机的栈帧，所以轻量级锁和 HashCode 是可以共存的。</li></ul><blockquote><p>并不是十分确定。</p></blockquote><br><h3><span id="自旋锁-amp-自适应自旋锁">自旋锁 &amp; 自适应自旋锁</span></h3><p>引入自旋锁是因为在很多时候线程并不会长时间持有锁，此时使用  Metux 阻塞线程没过一会儿又唤醒就得不偿失。</p><blockquote><p><strong>自旋锁就是一个循环，在等待持有锁的线程释放锁的过程中，不阻塞线程而让线程处于一直循环尝试获取锁的状态，从而避免了线程切换，阻塞的开销。</strong></p></blockquote><p>自旋锁在自旋的过程中也会占用一部分的 CPU 时间，若一直无限制自旋也会白白浪费 CPU 资源，所以在此基础之上又引入了<strong>自适应自旋锁</strong>.</p><p>自适应自旋锁是对自旋锁的优化，<strong>为自旋的次数或者时间设定一个上限，若超过这个上限一般会选择挂起线程或别的操作.</strong></p><br><h3><span id="锁消除">锁消除</span></h3><p>锁消除就是<strong>在逃逸分析技术的支持下</strong>，消除非公用资源的上锁步骤，从而提高性能。</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">test</span><span class="hljs-params">()</span>&#123;<br>    <span class="hljs-type">StringBuffer</span> <span class="hljs-variable">s</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">StringBuffer</span>();<br>    <span class="hljs-type">String</span> <span class="hljs-variable">a1</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;CheN&quot;</span>;<br>    <span class="hljs-type">String</span> <span class="hljs-variable">a2</span> <span class="hljs-operator">=</span> <span class="hljs-string">&quot;bXxx&quot;</span>;<br>    s.append(a1);<br>    s.append(a2);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>如上面这段代码展示，其中 StringBuffer 类是线程安全的，方法都会有 synchronized 修饰，所以最少也会有偏向锁的机制在发挥作用，但 a1 和 a2 的作用域就在 test 方法中，完全不会逃逸到方法体外，也不会引起线程安全问题，此时甚至偏向锁都显得很没必要。</p><br><h3><span id="锁粗化">锁粗化</span></h3><p>在一段代码中，若同步区域被限制的过小会导致线程频繁的进行锁的释放和获取操作.而此时锁粗化的作用就出来了，<strong>虚拟机探测到该类情况会直接将锁的同步区域扩展到整个操作的外部</strong>，从而消除无谓的锁操作。</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;i &lt; <span class="hljs-number">10</span>;i++)&#123;<br>    <span class="hljs-comment">// 此时虚拟机会直接将锁的范围扩展到循环之外</span><br>    <span class="hljs-keyword">synchronized</span>(<span class="hljs-built_in">this</span>)&#123;<br>      doSomething();<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><br><br><h2><span id="相关文章">相关文章</span></h2><ul><li><a href="https://blog.csdn.net/javazejian/article/details/72828483">深入理解Java并发之synchronized实现原理</a></li><li><a href="https://juejin.im/post/5b42c2546fb9a04f8751eabc">Java并发——关键字synchronized解析</a></li><li><a href="https://blog.csdn.net/saintyyu/article/details/108295657">HashCode和偏向锁</a></li><li><a href="https://mp.weixin.qq.com/s?__biz=MzkxNTE3NjQ3MA==&mid=2247488192&idx=1&sn=85fa12be29fef85d41c571b2c853de5d&chksm=c1627fb9f615f6af30d979b3e69bd7223e9e5e3e801a59f12cd492d00ea32623d55177f5e523&mpshare=1&scene=24&srcid=03027ZCVnPeq49L3bb4hjg9z&sharer_sharetime=1614644481827&sharer_shareid=22f066e400946fcffb59089626c6a1f2#rd">synchronized的源码级理解</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jvm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>RabbitMQ 如何保证消息不丢失</title>
    <link href="/2021/06/16/RabbitMQ%20%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/"/>
    <url>/2021/06/16/RabbitMQ%20%E5%A6%82%E4%BD%95%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1/</url>
    
    <content type="html"><![CDATA[<h1><span id="rabbitmq-如何保证消息不丢失">RabbitMQ 如何保证消息不丢失?</span></h1><hr><br><h2><span id="脑图">脑图</span></h2><p><img src="/assets/RabbitMQ%E8%84%91%E5%9B%BE1-7942529.png" alt="相关脑图"></p><br><br><h2><span id="概述">概述</span></h2><p>RabbitMQ 可以分为 Producer（生产者），Consumer（消费者），Exchange（交换机），Queue（队列）四个角色。</p><p>消息的流经过程就是 Producer -&gt; Exchange -&gt; Queue -&gt; Consumer。</p><blockquote><p>和 Kafka 不同，RabbitMQ 不会直接和 Queue（Topic） 打交道，而是通过 Exchange，生产者甚至不知道消息最终去了哪里。</p></blockquote><br><p>所以要保证消息不丢就必须保证以下流程：</p><ol><li>Producer 到 Exchange 的过程，确保 Exchange 接收到消息</li><li>Exchange 到 Queue 的过程，确保消息被正确的投递</li><li>Queue 到 Consumer 的过程，确保消息被正常的消费和 ack</li></ol><p>还有就是，消息在 Exchange 和 Queue 的持久性，不能因为 Broker 的宕机导致消息的丢失，所以 Exchange ，Queue 和消息都需要持久化。</p><blockquote><p>持久化对性能有损，使用时谨慎判断是否必要。</p></blockquote><br><br><h2><span id="producer-到-exchange-的过程">Producer 到 Exchange 的过程</span></h2><p>该过程可以通过<a href="https://www.rabbitmq.com/tutorials/tutorial-seven-java.html">生产者确认（Publisher Confirm）</a> 来保证。</p><p><strong>Confirm 机制开启之后，会为生产者的每条消息添加从1开始的id，如果 Broker 确定接收到消息，则返回一个 confirm。</strong></p><p>Confirm 机制只负责到消息是否到达 Exchange 不负责后续的消息投递等流程，另外 RabbitMQ 也提供了事务的情况，事务的作用就是确保消息一定能够全部到达 Broker。</p><br><p>Springboot 的 RabbitMQ 实现中，可以对 RabbitTemplate 添加 RabbitTemplate.ConfirmCallback 回调函数，该回调需要额外配置以下内容</p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/rabbitmq-publish-confirm配置.png" alt="rabbitmq-publish-confirm配置" style="zoom:67%;"><p><strong>confirm 的回调方法在消息投递出去之后触发，不论成功还是失败都会。</strong></p><p>以回执的方式明确消息是否真正到达 Broker，如果未到达则可以做下一步的处理，重发或者入库等等，方法相关入参如下：</p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/rabbitmq-publish-confirm示例.png" alt="rabbitmq-publish-confirm示例" style="zoom:67%;"><br><br><h2><span id="exchange-到-queue-的过程">Exchange 到 Queue 的过程</span></h2><p><strong>该过程可以通过 RabbitMQ 提供的 mandatory 参数设置。</strong></p><p>mandatory 参数的作用就是确保消息被正确的投递到具体的队列，如果在 Broker 中无法匹配到具体队列，那么也会触发回调。</p><br><p>Springboot 的客户端封装也提供了 RabbitTemplate.ReturnCallback 回调方法，用来监听消息的状态。</p><p>想要该参数生效，以下两个配置必须同时配置。</p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/rabbitmq-springboot-mandatory配置.png" alt="rabbitmq-springboot-mandatory配置" style="zoom:67%;"><p>方法相关入参如下：</p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/rabbitmq-mandatory回调示例.png" alt="rabbitmq-mandatory回调示例" style="zoom:67%;"><br><p>回调并没有办法直接解决消息的投递失败问题，对失败投递进行报警，然后人工排查情况才是关键。</p><blockquote><p>mandatory 的回调只有消息投递失败的时候才会触发，正常投递不会触发。</p><p>这和 publish confirm 不同，publish confirm 是不管失败还是成功都会触发回调的。</p></blockquote><br><h3><span id="备份交换机">备份交换机</span></h3><p><strong>RabbitMQ 中还存在一个备份交换机（alternate-exchange）的概念，如果消息在正常的交换机无法匹配到队列的时候，消息会被转发到该交换机，由该交换机进一步投递。</strong></p><p><strong>所以就可以使用备份交换机收集无法匹配到 Queue 的消息。</strong></p><p>一般该交换机被设置为 FANOUT 模式，确保消息可以被直接投递。</p><br><br><h2><span id="queue-到-consumer-的过程">Queue 到 Consumer 的过程</span></h2><p>RabbitMQ 中保存的消息，只有在被 ack 之后才会主动删除，所以在 ack 消息之前必须要确保消息的正常消费。</p><blockquote><p>这个也是 RabbitMQ 和 Kafka 不同的点。</p><p>Kafka 在消费者 ack 之后并不会删除消息，只有消息累积到一定阈值（时间或者大小）之后才会删除，甚至可以不删除，因此 Kafka 即使作为存储服务也没啥问题。</p></blockquote><br><h3><span id="rabbitmq-原生-ack-模式">RabbitMQ 原生 ack 模式</span></h3><p>RabbitMQ 的消费者端提供了<strong>自动和手动两种 ack 方式</strong>。</p><p><a href="https://www.rabbitmq.com/confirms.html#acknowledgement-modes">Consumer Acknowledgement Modes and Data Safety Considerations</a></p><p><strong>在自动确认的模式下，消息被认为在发送之后就算成功处理，因此很容易造成消息丢失，但是自动确认在很大程度上提高了吞吐量。</strong></p><blockquote><p>Consumer 是直接和 Queue 接触的，一个 Queue 可以由多个 Consumer 共同消费，如果一个 Consumer 断线，那么该 Consumer 上未 ack 的消息会被转发到其他的 Consumer 上，此时又会存在重复消费的问题。</p></blockquote><p><strong>对于手动确认</strong>，RabbitMQ 定义了以下三种形式：<img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/rabbitmq%E6%89%8B%E5%8A%A8ack%E7%B1%BB%E5%9E%8B.png" alt="rabbitmq手动ack类型"></p><br><p>basic.ack 就是确认消费成功，Broker 在接收到该条 ack 之后会尝试删除对应的消息。</p><p>basic.reject 和 basic.nack 的作用是一样的，区别就在于语义上，作用都是拒绝消息，并且可以通过参数确定消息是否需要重新入队列。</p><br><blockquote><p><strong>消费者连接的时候就需要指定 ack 的模式。</strong></p><p>RabbitMQ 提供了两大类 ack 模式：手动和自动</p><ol><li>自动 ack 会在消息到达消费者之后直接删除队列中的消息</li><li>手动 ack 分为 ack &#x2F; nack &#x2F; reject 三种。</li></ol></blockquote><br><br><h3><span id="java-原生客户端-ack-实现">Java 原生客户端 ack 实现</span></h3><p>在创建 Consumer 的时候就需要指定 ack 的形式:</p><p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/rabbitmq-%E5%88%9B%E5%BB%BAconsumer.png" alt="rabbitmq-创建consumer"></p><p>上图中的方法参数 autoAck 就表示是否开启<strong>自动 ack</strong>。</p><p>对于三种手动确认的方法也分别提供了方法。</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">void</span> <span class="hljs-title function_">basicAck</span><span class="hljs-params">(<span class="hljs-type">long</span> deliveryTag, <span class="hljs-type">boolean</span> multiple)</span> <span class="hljs-keyword">throws</span> IOException;<br>    <br><span class="hljs-keyword">void</span> <span class="hljs-title function_">basicNack</span><span class="hljs-params">(<span class="hljs-type">long</span> deliveryTag, <span class="hljs-type">boolean</span> multiple, <span class="hljs-type">boolean</span> requeue)</span><br>            <span class="hljs-keyword">throws</span> IOException;<br><br><span class="hljs-keyword">void</span> <span class="hljs-title function_">basicReject</span><span class="hljs-params">(<span class="hljs-type">long</span> deliveryTag, <span class="hljs-type">boolean</span> requeue)</span> <span class="hljs-keyword">throws</span> IOException;<br></code></pre></div></td></tr></table></figure><p>deliveryTag 可以简单理解为消息的 id。</p><p>multiple 参数的含义是是否为批量操作，例如 basicAck 方法，如果为批量操作，会将 deliveryTag 之前的消息都 ack。</p><p>requeue 参数表示是否需要重回队列，如果为 false，那么在方法调用后消息就会被丢弃或者转发到死信队列，如果为 true，消息就会重新进入队列，重新下发到消费者。</p><blockquote><p>Java 原生的 RabbitMQ 客户端基本就简单实现了。</p></blockquote><br><h3><span id="springboot-中的-ack-实现">SpringBoot 中的 ack 实现</span></h3><p>SpringBoot 根据以上的 ack 方法抽象提供了三种 AcknowledgeMode，具体如下：</p><img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/springboot-rabbitmq-ackmode.png" alt="springboot-rabbitmq-ackmode" style="zoom:67%;"><p>None 对应的就是 RabbitMQ 的 自动 ack，在消息被下发后就认为是消费成功，Broker 可以删除该消息。</p><blockquote><p>实际开发中慎用该配置！</p><p>但是如果处理失败就无法对该条消息进行重试，因为已经从队列中删除。</p><p>自动 ack 能稍微提高消息速度，ack 之后 Broken 会立马补消息到 prefetch 个。</p></blockquote><p>MANUAL 需要用户在 listener 中手动调用 ack &#x2F; nack &#x2F; reject 方法。</p><p><strong>AUTO 是由 SpringBoot 控制的 ack 模式，如果 listener 返回正常，则调用 ack，如果抛异常则调用 nack。</strong></p><blockquote><p>是在 RabbitMQ 官方提供了客户端实现的基础上封装的记住。</p></blockquote><p>另外的还有 default-requeue-rejected 配置，表示在消息处理失败之后是否需要重回队列。</p><blockquote><p><strong>SpringBoot 的客户端默认是会重回队列的，所以如果 Listener 抛异常而不进一步处理，消息会进入死循环。</strong></p></blockquote><br><h2><span id="阅读">阅读</span></h2><p><a href="https://www.rabbitmq.com/confirms.html#publisher-confirms">Consumer Acknowledgements and Publisher Confirms</a></p>]]></content>
    
    
    <categories>
      
      <category>rabbitmq</category>
      
    </categories>
    
    
    <tags>
      
      <tag>mq</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅析 JVM 类加载子系统</title>
    <link href="/2021/06/05/%E6%B5%85%E6%9E%90-JVM-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/"/>
    <url>/2021/06/05/%E6%B5%85%E6%9E%90-JVM-%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1><span id="类加载子系统">类加载子系统</span></h1><h2><span id="思维导图">思维导图</span></h2><p><img src="/assets/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%AD%90%E7%B3%BB%E7%BB%9F-7942505.png" alt="JVM 类加载子系统"></p><br><br><h2><span id="概述">概述</span></h2><p>Java 的类加载子系统负责从网络或者本地文件等多途径获取以 .class 结尾的字节码文件，并解析成基本的 Class 类型。</p><p>加载子系统只负责类的加载，保证类的安全性，执行还是交给执行子系统的。</p><br><br><h2><span id="类加载的流程">类加载的流程</span></h2><div class="hljs code-wrapper"><pre class="mermaid">graph LR subgraph B [链接] D[验证] --> E[准备] E --> F[解析] endA[ 加载] --> DF --> H[初始化]</pre></div><p><strong>实际的类加载流程是交叉进行的，并不是线程执行，</strong>例如加载到二进制流之后，验证就会开始文件结构验证。</p><br><ul><li>加载</li></ul><p>加载就是通过<strong>类的全限定名</strong>获取该类的字节码文件的二进制流，并将其转化为运行时的数据结构，也就是 Class 文件。</p><br><ul><li>验证</li></ul><p>验证是指对二进制流的验证，验证是否满足 JVM 的规范，是否会威胁到 JVM 自身的运行。</p><p>验证细分有以下四个部分：<strong>文件结构验证，元数据验证，字节码验证，符号引用验证</strong>。</p><p>在文件结构验证时候，二进制流就转化为了运行时数据结构，以后的验证都是对运行时结构的验证。</p><p>符号引用验证会在解析的时候执行。</p><br><ul><li>准备</li></ul><p>准备过程是给类变量分配空间的过程，并且回给类变量赋系统初值。</p><p>系统初值是指 JVM 默认的值，例如 boolean 类型默认会为 false 等。</p><br><ul><li>解析</li></ul><p>解析是对符号引用的解析，确保符号引用是全部有效，并将其转化为直接引用。</p><p>Class 文件常量池中就包含了一部分的符号引用。</p><br><ul><li>初始化</li></ul><p>初始化是执行 <code>&lt;cinit&gt;</code> 的过程。</p><p><code>&lt;cinit&gt;</code>  就是从类文件中收集的包括静态初始化快，字面量初始化等等的语句。</p><blockquote><p>有一个注意点是静态初始化块是从上到下顺序加载并执行的，并且先于构造函数的 <init> 执行。</init></p></blockquote><br><br><h3><span id="class-加载和卸载">Class 加载和卸载</span></h3><ul><li>加载的时机</li></ul><ol><li>创建类实例对象的时候，通过 new，reflect 等途径 </li><li>调用类的静态方法或者访问类的静态变量的时候</li><li>初始化子类时发现父类未加载，会先加载父类</li></ol><blockquote><p>不全，代补充。</p></blockquote><br><ul><li>卸载的时机</li></ul><ol><li>该类所有的实例都已被回收</li><li>该类的 ClassLoader 已经被回收</li><li>该类的 Class 对象没有在任何地方被引用</li></ol><br><h3><span id="class-对象的存放">Class 对象的存放</span></h3><p>类加载器加载 Class 文件，输出一个 Class 类，该类的信息都保存在<strong>元空间</strong>（1.8及以上版本），元空间是一片直接内存，会以 ClassLoader 为单位划分区域，每个 ClassLoader 还会保存各自加载过的类。</p><p>装载过程中，字面量，常量会加入到各自的运行时常量池，部分符号引用此时会被解析为直接引用，另外还会保存一份虚方法表。</p><br><br><h2><span id="基本的类加载器">基本的类加载器</span></h2><div class="hljs code-wrapper"><pre class="mermaid">graph TDA[Bootstrap ClassLoader] --> B[Extension ClassLoader] B --> C[Application ClassLoader]</pre></div><p>以上是 JDK 中提供的三种基础的类加载器。</p><ul><li>Bootstrap ClassLoader</li></ul><p>该类加载器使用 C 语言实现，直接内置在 JVM，用于加载 Java 核心库，例如 rt.jar 或者 bootstrap 目录下的依赖。</p><p>并且出于安全考虑，该加载器只会加载 java，javax，sun 开头的类。</p><br><ul><li>Extension ClassLoader</li></ul><p>扩展的类加载器，使用 Java 语言编写，具体实现为 sun.misc.Launcher$ExtClassLoader。</p><p>用于加载 &#x2F;jre&#x2F;lib&#x2F;ext 下的类库，以 Bootstrap ClassLoader 为其父类</p><br><ul><li>Application ClassLoader</li></ul><p>应用类加载器，具体实现为 sun.misc.Launcher$AppClassLoader。</p><p>用于加载 CLASSPATH 目录下的类，为 ExtClassLoader 的子类。</p><br><blockquote><p>Bootstrap 和 Extension 两个加载器扫描的类的目录已经被限定死了，这是后续 SPI 等实现必须要通过 TCCL 的原因之一。</p></blockquote><br><blockquote><p>还有一点重要的，Java 中判断两个 Class 是否相等，除了其本身还需要判断对应的类加载器是否一致，同个 Class 文件被不同的 ClassLoader 装载就是不同的 Class 对象。</p></blockquote><br><h2><span id="classloader-的基础实现">ClassLoader 的基础实现</span></h2><p>ExtClassLoader 和 AppClassLoader 都定义在 sun.misc.Launcher 中的，Launcher 是 Java 程序启动的起点。</p><br><h3><span id="launcher-的初始化">Launcher 的初始化</span></h3><p>介绍 ExtClassLoader 和 AppClassLoader 两种基本类加载器的创建过程。</p><blockquote><p>Bootstrap 是内置在 JVM 中的，Java 程序启动的时候就是由 Bootstrap 先加载 Launcher 对象。</p></blockquote><br><img src="assets/Launcher构造函数-7942515.png" alt="Launcher构造函数" style="zoom:67%;"><p>上图， Launcher 的构造函数中主要就包含了以下三个逻辑：</p><ul><li>创建 ExtClassLoader</li><li>以 ExtClassLoader 为参数，创建 AppClassLoader</li><li><strong>设置当前线程上下文加载器为 AppClassLoader</strong></li></ul><br><br><h3><span id="classloader-的实现">ClassLoader 的实现</span></h3><p>AppClassLoader 和 ExtClassLoader 都继承于 URLClassLoader，而 URLClassLoader 又是继承与 ClassLoader 的。</p><p>ClassLoader 中分别有以下几种重点方法：</p><table><thead><tr><th>方法名</th><th>作用</th></tr></thead><tbody><tr><td>loadClass(String,boolean)</td><td>加载指定的 Class 文件的二进制流数据，boolean 表示是否对 Class 对象进行解析</td></tr><tr><td>findClass(String)</td><td>搜索 Class 文件，入参为类的全限定名</td></tr><tr><td>defineClass(byte[] b, int off, int len)</td><td>该方法用于将 byte 字节流解析成 Class 对象，入参就是 byte 数组。</td></tr><tr><td>resolveClass(Class≺?≻ c)</td><td>解析并初始化 Class 类</td></tr></tbody></table><br><h4><span id="loadclassstring">#loadClass(String)</span></h4><p>该方法是 ClassLoader 中最主要的方法，<strong>双亲委派机制</strong> 就是在该方法中实现的，<code>ClassLoader.loadClass</code> 也是常用的用于加载某个类的常用方法。</p><blockquote><p>有个容易忽略的点是，该方法可以获得 Class 类，但是并不会触发 Class 类的初始化，也就是类加载的最后一步。</p><p>但 Class.forName 会触发类的初始化，</p></blockquote><br><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// ClassLoader#loadClass</span><br><span class="hljs-keyword">protected</span> Class&lt;?&gt; loadClass(String name, <span class="hljs-type">boolean</span> resolve)<br>    <span class="hljs-keyword">throws</span> ClassNotFoundException<br>&#123;<br>    <span class="hljs-keyword">synchronized</span> (getClassLoadingLock(name)) &#123;<br>        <span class="hljs-comment">// First, check if the class has already been loaded</span><br>        <span class="hljs-comment">// 通过缓存查找是否被该类加载器加载过。</span><br>        Class&lt;?&gt; c = findLoadedClass(name);<br>        <span class="hljs-keyword">if</span> (c == <span class="hljs-literal">null</span>) &#123;<br>            <span class="hljs-type">long</span> <span class="hljs-variable">t0</span> <span class="hljs-operator">=</span> System.nanoTime();<br>            <span class="hljs-keyword">try</span> &#123;<br>                <span class="hljs-keyword">if</span> (parent != <span class="hljs-literal">null</span>) &#123;<br>                    <span class="hljs-comment">// 通过父类加载器，加载 name 类</span><br>                    c = parent.loadClass(name, <span class="hljs-literal">false</span>);<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-comment">// 直接通过 Bootstrap 加载类</span><br>                    c = findBootstrapClassOrNull(name);<br>                &#125;<br>...<br><br>            <span class="hljs-comment">// 都找不到</span><br>            <span class="hljs-keyword">if</span> (c == <span class="hljs-literal">null</span>) &#123;<br>                ...<br>                <span class="hljs-comment">// 调用 findClass 方法获取 Class 类</span><br>                c = findClass(name);<br>...<br>            &#125;<br>        &#125;<br>        <span class="hljs-comment">// 是否需要解析</span><br>        <span class="hljs-keyword">if</span> (resolve) &#123;<br>            <span class="hljs-comment">// 需要就调用 resolveClass </span><br>            resolveClass(c);<br>        &#125;<br>        <span class="hljs-keyword">return</span> c;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><p>从上面的代码可以大概的看出类加载的逻辑:</p><ol><li><strong>尝试从缓存中获取 Class</strong></li><li><strong>通过 父类 或者 Bootstrap 获取 Class</strong></li><li><strong>通过 findClass 方法获取 Class</strong></li></ol><p>以上三种就是 Class 对象的主要获取方式，之后根据参数会判断是否需要调用 resolveClass 方法进行解析。</p><p>最后调用的 findClass 方法在 ClassLoader 中是一个空方法，也就是模板方法，等待子类继承实现，URLClassLoader 就实现了该方法。</p><p>另外在方法的注释上也表明，<strong>实现者推荐开发者实现 findClass 方法，而并不推荐直接重写 loadClass 方法。</strong></p><br><br><h2><span id="双亲委派机制">双亲委派机制</span></h2><p>上文说的，ClassLoader#loadClass 方法中实现了双亲委派机制的基础逻辑。</p><p><strong>所有加载的类都会优先由父类加载，从下往上传递类加载任务，如果父类无法加载再由子类进行加载。</strong></p><blockquote><p>实现中可以看到，即使没有父类加载器，也会先从 Bootstrap 加载目标类，这就保证了 Java 核心类库的安全。</p></blockquote><br><p>双亲委派的优势:</p><ol><li>避免了类的重复加载，父子之间就是一条责任链，父类加载过的类不需要子类重新加载。</li><li>提高了程序的安全性，类似 java.lang.String 就只能通过 Bootstrap 加载</li></ol><blockquote><p>代补充。</p></blockquote><p>双亲委派机制的层次性是自下而上的，下级的类加载器共享上级的类加载器所加载的类，但是下级加载的类堆上级是不可见的。</p><br><br><h2><span id="线程上下文类加载器">线程上下文类加载器</span></h2><p>在 Launcher 的构造函数中就出现了相关逻辑，<strong>设置了 AppClassLoader 作为当前线程的上下文加载器</strong>。</p><p>线程上下文加载器可以当做是将类加载器和线程绑定，在线程中保存一份加载器的引用，因此在任何地方都可以获取到当期线程的上下文类加载器。</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// 获取当前线程上下文类加载器的方法</span><br>Thread.currentThread().getContextClassLoader();<br></code></pre></div></td></tr></table></figure><p><strong>该方法的出现就是为了打破双亲委派机制</strong>。</p><p>在双亲委派机制中，类加载的任务是从下往上传递的，但是总有一些意外情况，比如 Java 核心类库中的类需要加载第三方类库的实现，比如 ServiceLoader 实现的 SPI 机制。</p><p>Java 核心类库都是通过 Bootstrap 实现的，但是因为 Bootstrap 被限定了目录以及类路径前缀，所以无法被用来加载 ServiceLoader，此时就可以通过 线程上下文类加载器 实现高层的类加载器调用底层去加载类的逻辑。</p><br><blockquote><p>非常重要的一点：</p><p><strong>类优先由触发类加载的类所属的类加载器加载。</strong></p></blockquote><br><br><h2><span id="打破双亲委派机制的实例">打破双亲委派机制的实例</span></h2><h3><span id="tomcat-的类加载机制">Tomcat 的类加载机制</span></h3><p>Tomcat 作为一个 Web Servlet 容器，肯定需要装载多个 Web 应用，多个应用之间的依赖库不可能完全一致，可能出现同个依赖不同版本的情况，也可能出现两个应用之间类名相同的情况，这个时候就需要在多个 WebApp 之间做类上的隔离，另外同一个应用不可能说相同的依赖还需要重复加载几次，所以也存在依赖复用的情况。</p><p>另外 Tomcat 还提供了 Jsp 的热加载功能，动态的卸载和加载 Jsp 类。</p><blockquote><p>JSP 最后会被转化为 Class 然后执行输出。</p></blockquote><div class="hljs code-wrapper"><pre class="mermaid">graph TDA[Bootstrap ClassLoader] --> B[Extension ClassLoader] B --> C[Application ClassLoader]C --> D[Common ClassLoader]D --> E[Catalina ClassLoader]D --> F[Shared ClassLoader]F --> G[WebApp ClassLoader]G --> H[Jsp ClassLoader]</pre></div><p>所以 Tomcat 设计了如上的一套类加载体系。</p><p>除开三种基础的类加载器，Common 就是 Tomcat 中最上层的，他加载的类对所有的 Web 应用共享，并且对 Tomcat 自身也是共享的。</p><p>Catalina 负责加载的是 Tomcat 专用的一些类，比如 Tomcat 中的 Connector 等一些基础组件，这些对 Web 应用来说是不可见的，是隔离开的。</p><p>Shared 负责加载的是所有的 Web 引用共享的类，它和 Catalina 相隔离，互相不可见。</p><p>WebApp 负责加载当应用的类库，一个应用就对应这一个 WebApp 类加载器，相互之间隔离互相不影响，并且共享 Shared 类加载器加载的共用类。</p><p>Jsp 比较特别，它是每一个类一个类加载器，用于在 Jsp 文件修改之后做热更新。</p><blockquote><p>Common，Catalina 以及 Shared 都有指定的目录，不过不是本文的重点就不说了。</p></blockquote><br><p><strong>通过以上的体系，Tomcat 实现了类之间隔离和共享的关系区分。</strong></p><p>实现上 Catalina 和 Common 以及 Shared 都是 URLClassLoader，还是遵从的双亲委派机制的。</p><p>但是 WebApp 是单独实现的，继承了 URLClassLoader，并重写了 loadClass 方法，在查找了当前的 ClassLoader 的缓存之后，并没有直接使用父类加载器加载，而是继续在本地查找，找不到再去父类查找。</p><br><h3><span id="jdk-的-spi-实现-jdbc-driver-实现的加载">JDK 的 SPI 实现 - JDBC Driver 实现的加载</span></h3><p>JDBC 的核心类定义在 Java 的核心库，由 Bootstrap 加载，但是三方的实现却是在 ClassPath 里，需要使用 Application 来加载。</p><p>在 Java 的核心类加载三方实现的时候默认就是从  Application 加载，此时就会出现 ClassNotFound。</p><br><p><strong>JDBC 就在采用的方法就是 TCCL (Thread Context Class Loader) 线程上下文类加载器。</strong></p><p>在核心类中获取当前线程中绑定的类加载器，由此优先高级别类加载器调用低级别类加载器的实现。</p><br><p>参考 DriverManager 获取 Driver 的实现。</p><p>首先该类的静态初始化块中就包含了 Driver 的类加载流程。</p><img src="assets/DriverManager的静态初始化块-7942519.png" alt="DriverManager 的静态初始化块" style="zoom:80%;"><p>在 loadInitialDrivers 方法中调用了 ServiceLoader 的 load 方法：</p><img src="assets/DriverManager11loadInitialDrivers-7942521.png" alt="loadInitialDrivers" style="zoom:67%;"><p>而在 ServiceLoader 中就包含了对线程上下文类加载器的调用：</p><img src="assets/ServerLoader11load-7942523.png" alt="ServerLoader#load" style="zoom:67%;"><br><br><h3><span id="spring-的类加载机制">Spring 的类加载机制</span></h3><p>Spring 的类加载场景比较复杂，所以基本是统一采用 TCCL 来实现类加载，Spring 研究不多，待补充。</p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jvm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ThreadLocal 源码分析</title>
    <link href="/2021/05/30/ThreadLocal%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/"/>
    <url>/2021/05/30/ThreadLocal%E5%AE%9E%E7%8E%B0%E8%A7%A3%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1><span id="threadlocal">ThreadLocal</span></h1><h2><span id="思维导图">思维导图</span></h2><p><img src="/assets/ThreadLocal.png" alt="ThreadLocal思维导图"></p><br><h2><span id="概述">概述</span></h2><p>ThreadLocal（线程局部变量），作用是<strong>保存每个线程的私有变量</strong>，以空间换时间的方式，为每一个线程保存一份<strong>私有</strong>变量，也就不存在所谓的并发问题。</p><blockquote><p>真实的数据并不会存在 ThreadLocal 中。</p><p>实际上，数据都保存在 Thread 对象中 Thread#threadLocals 这个成员变量里，所以一定程度上 ThreadLocal 只是一个操作该集合的工具类。</p></blockquote><br><p>以下就是 ThreadLocalMap 在Thread中的变量声明:</p><p> <img src="https://chenqwwq.oss-cn-hangzhou.aliyuncs.com/note/assets/ThreadLocalMap%E7%9A%84%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E.png" alt="ThreadLocalMap的变量声明"></p><blockquote><p>threadLocals 是给 ThreadLocal 用的，该类只能访问当前线程中的数据。</p><p>inheritableThreadLocal 是给 InheritableThreadLocal 用的，使用该类子线程可以访问到父线程的数据。</p></blockquote><br><h2><span id="threadlocal-的相关操作">ThreadLocal 的相关操作</span></h2><ul><li><code>ThreadLocal</code>的内部方法因为逻辑都不复杂,不需要单独出来看,就直接全放一块了.</li></ul><h3><span id="数据获取-get">数据获取 - Get</span></h3><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java">  <span class="hljs-comment">// 直接获取线程私有的数据</span><br>  <span class="hljs-keyword">public</span> T <span class="hljs-title function_">get</span><span class="hljs-params">()</span> &#123;<br>       <span class="hljs-comment">// 获取当前线程</span><br>       <span class="hljs-type">Thread</span> <span class="hljs-variable">t</span> <span class="hljs-operator">=</span> Thread.currentThread();<br>       <span class="hljs-comment">// getMap其实很简单就是获取`t`中的`threadLocals`,代码在`工具方法`中</span><br>       <span class="hljs-type">ThreadLocalMap</span> <span class="hljs-variable">map</span> <span class="hljs-operator">=</span> getMap(t); <br>       <span class="hljs-keyword">if</span> (map != <span class="hljs-literal">null</span>) &#123;<span class="hljs-comment">// 3.</span><br>           ThreadLocalMap.<span class="hljs-type">Entry</span> <span class="hljs-variable">e</span> <span class="hljs-operator">=</span> map.getEntry(<span class="hljs-built_in">this</span>);<br>           <span class="hljs-keyword">if</span> (e != <span class="hljs-literal">null</span>) &#123;<span class="hljs-comment">// 2.</span><br>               <span class="hljs-meta">@SuppressWarnings(&quot;unchecked&quot;)</span><br>               <span class="hljs-type">T</span> <span class="hljs-variable">result</span> <span class="hljs-operator">=</span> (T)e.value;<br>               <span class="hljs-keyword">return</span> result;<br>           &#125;<br>       &#125;<br>       <span class="hljs-keyword">return</span> setInitialValue();  <span class="hljs-comment">// 1.</span><br>   &#125;<br><span class="hljs-comment">// 这个方法只有在上面`1.`处调用...不知道为什么map,thread不直接传参</span><br><span class="hljs-comment">// 该方法的功能就是为`Thread`设置`threadLocals`的初始值</span><br>   <span class="hljs-keyword">private</span> T <span class="hljs-title function_">setInitialValue</span><span class="hljs-params">()</span> &#123;<br>       <span class="hljs-type">T</span> <span class="hljs-variable">value</span> <span class="hljs-operator">=</span> initialValue();<br>       <span class="hljs-type">Thread</span> <span class="hljs-variable">t</span> <span class="hljs-operator">=</span> Thread.currentThread();<br>       <span class="hljs-type">ThreadLocalMap</span> <span class="hljs-variable">map</span> <span class="hljs-operator">=</span> getMap(t);<br>       <span class="hljs-comment">// map不为null表明是从上面的`2.`处进入该方法</span><br>       <span class="hljs-comment">// 已经初始化`threadLocals`,但并未找到当前对应的`Entry`</span><br>       <span class="hljs-comment">// 所以此时直接添加`Entry`就行</span><br>       <span class="hljs-keyword">if</span> (map != <span class="hljs-literal">null</span>)<br>           map.set(<span class="hljs-built_in">this</span>, value);<br>       <span class="hljs-keyword">else</span><br>           createMap(t, value);<br>       <span class="hljs-keyword">return</span> value;<br>   &#125;<br>     <span class="hljs-comment">// 初始值,`protected`方便子类继承,并定义自己的初始值.</span><br>     <span class="hljs-keyword">protected</span> T <span class="hljs-title function_">initialValue</span><span class="hljs-params">()</span> &#123;<br>       <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>     &#125;<br><br><span class="hljs-comment">// 创建并赋值`threadLocals`的方法</span><br>    <span class="hljs-keyword">void</span> <span class="hljs-title function_">createMap</span><span class="hljs-params">(Thread t, T firstValue)</span> &#123;<br>       t.threadLocals = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ThreadLocalMap</span>(<span class="hljs-built_in">this</span>, firstValue);<br>   &#125;<br></code></pre></div></td></tr></table></figure><p>整个获取的过程其实并不难：</p><ol><li>通过 Thread#currentThread 方法获取当前线程对象。</li><li>首先通过 getMap 方法获取当前线程绑定的 threadLocals。</li><li>不要为空时，以当前 ThreadLocal 对象为参数获取对应的Entry 对象，为空跳到第四步。</li><li>获取 Entry 对象中的 value ，并返回。</li><li>调用 setInitialValue方法，并返回。</li></ol><br><p>这里可以很明显的看出来，数据其实还是保存在 Thread 对象里的。</p><p>通过 setInitialValue 方法可以设定初始值。</p><blockquote><p>例如，希望统计每个线程的某个操作计数，那么就可以用如下的方法：</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java">ThreadLocal&lt;Integer&gt; counter = <span class="hljs-keyword">new</span> <span class="hljs-title class_">ThreadLocal</span>&lt;Integer&gt;() &#123;<br>    <span class="hljs-meta">@Override</span><br>    <span class="hljs-keyword">protected</span> Integer <span class="hljs-title function_">initialValue</span><span class="hljs-params">()</span> &#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;;<br></code></pre></div></td></tr></table></figure><p>以 0 为初始值做统计。</p></blockquote><br><br><h3><span id="数据存储-set">数据存储 - Set</span></h3><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">public</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">set</span><span class="hljs-params">(T value)</span> &#123;<br>       <span class="hljs-comment">// 获取当前线程</span><br>       <span class="hljs-type">Thread</span> <span class="hljs-variable">t</span> <span class="hljs-operator">=</span> Thread.currentThread();<br>       <span class="hljs-type">ThreadLocalMap</span> <span class="hljs-variable">map</span> <span class="hljs-operator">=</span> getMap(t);     <span class="hljs-comment">// .1</span><br>       <span class="hljs-keyword">if</span> (map != <span class="hljs-literal">null</span>)<br>           map.set(<span class="hljs-built_in">this</span>, value);<br>       <span class="hljs-keyword">else</span><br>           createMap(t, value);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>流程简述如下：</p><ol><li>获取当前线程,并以此获取线程绑定的 ThreadLocalMap 对象。</li><li>map 不为空时,直接set。</li><li>map 为空时需要先创建 Map 并赋值。</li></ol><p><br><br></p><h2><span id="threadlocalmap">ThreadLocalMap</span></h2><p>ThreadLocalMap 类似于 HashMap ，也是使用 Hash 算法定位存取的数据结构，以 ThreadLocal 对象为 Key。</p><p>Hash 算法合理时 ThreadLocalMap 的存取操作近乎是 O(1) 的复杂度。</p><p><code>ThreadLocalMap</code> 出人意料的并没有继承任何一个类或接口，是完全独立的类，以为会像 HashMap 一样继承一下 AbstractMap。</p><br><h3><span id="成员变量">成员变量</span></h3>  <figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">// 默认的初始容量 一定要是二的次幂</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">INITIAL_CAPACITY</span> <span class="hljs-operator">=</span> <span class="hljs-number">16</span>;<br><span class="hljs-comment">// 元素数组/条目数组</span><br><span class="hljs-keyword">private</span> Entry[] table;<br><span class="hljs-comment">// 大小,用于记录数组中实际存在的Entry数目</span><br><span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-variable">size</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br><span class="hljs-comment">// 阈值</span><br><span class="hljs-keyword">private</span> <span class="hljs-type">int</span> threshold; <span class="hljs-comment">// Default to 0 构造方法</span><br></code></pre></div></td></tr></table></figure><blockquote><p><strong>ThreadLocalMap 的底层数据结构是 Entry 的数组，</strong>并且默认容量为16。</p></blockquote><br><p>以下为 Entry 对象的声明形式：</p><p> <img src="/assets/image-20210221154222208.png" alt="image-20210221154222208"></p><blockquote><p>WeakReference 声明了 Entry 对象对于 Key ，也就是 ThreadLocal 对象的引用是弱引用。</p><p><strong>弱引用消除了 ThreadLocalMap 的引用对 ThreadLocal  的对象回收的影响，</strong>这是 ThreadLocal 避免内存泄漏的核心。</p></blockquote><br><h3><span id="元素获取">元素获取</span></h3><h4><span id="getentrythreadlocalltgt-key">getEntry(ThreadLocal&lt;?&gt; key)</span></h4><ul><li>该方法就是通过 ThreadLocal 对象获取对应的数据。</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> Entry <span class="hljs-title function_">getEntry</span><span class="hljs-params">(ThreadLocal&lt;?&gt; key)</span> &#123;<br>    <span class="hljs-comment">// 和HashMap中一样的下标计算方式</span><br>    <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> key.threadLocalHashCode &amp; (table.length - <span class="hljs-number">1</span>);<br>    <span class="hljs-type">Entry</span> <span class="hljs-variable">e</span> <span class="hljs-operator">=</span> table[i];<br>    <span class="hljs-comment">// 获取到对应的Entry之后就分两步</span><br>    <span class="hljs-keyword">if</span> (e != <span class="hljs-literal">null</span> &amp;&amp; e.get() == key)<br>        <span class="hljs-comment">// 1. e不为空且threadLocal相等</span><br>        <span class="hljs-keyword">return</span> e;<br>    <span class="hljs-keyword">else</span><br>        <span class="hljs-comment">// 2. e为空或者threadLocal不相等</span><br>        <span class="hljs-keyword">return</span> getEntryAfterMiss(key, i, e);<br>&#125;<br></code></pre></div></td></tr></table></figure><p>起手就是一个 HashCode &amp; (len - 1)，和 HashMap 类似，但ThreadLocal 的 HashCode 和 HashMap 中的直接调用 hashCode() 方法不同。</p><p>ThreadLocal 是采用递增的形式，而非直接计算对象的 HashCode。</p><br> <figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">final</span> <span class="hljs-type">int</span> <span class="hljs-variable">threadLocalHashCode</span> <span class="hljs-operator">=</span> nextHashCode();<br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">AtomicInteger</span> <span class="hljs-variable">nextHashCode</span> <span class="hljs-operator">=</span> <span class="hljs-keyword">new</span> <span class="hljs-title class_">AtomicInteger</span>();  <br><span class="hljs-keyword">private</span> <span class="hljs-keyword">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">nextHashCode</span><span class="hljs-params">()</span> &#123;<br><span class="hljs-keyword">return</span> nextHashCode.getAndAdd(HASH_INCREMENT);<br>&#125;<br></code></pre></div></td></tr></table></figure><p> 以上就是 HashCode 的获取方式，<strong>是以类变量的方式递增获取</strong>，相对于直接调用 hashCode() 可以更好的减少 hash 冲突。</p><blockquote><p>每次创建一个 ThreadLocal，hashCode 都会+1，所以能使数据更加均匀的散布在数组中，更好的减少 hash 冲突。</p></blockquote><br><p>如果hash计算出来的下标存在想要的元素就直接返回，如果获取元素为空还会再调用 <code>getEntryAfterMiss</code> 做冲突查询的后续处理.</p><p><br><br></p><h4><span id="getentryaftermissthreadlocalltgt-key-int-i-entry-e">getEntryAfterMiss(ThreadLocal&lt;?&gt; key, int i, Entry e)</span></h4><ul><li>该方法是在直接按照 <code>Hash</code> 计算下标后，没获取到对应的 <code>Entry</code> 对象的时候调用，<strong>下标处不是想要的元素就说明出现了 Hash 冲突。</strong></li></ul><p>以下为方法源码：</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> Entry <span class="hljs-title function_">getEntryAfterMiss</span><span class="hljs-params">(ThreadLocal&lt;?&gt; key, <span class="hljs-type">int</span> i, Entry e)</span> &#123;<br>        Entry[] tab = table;<br>        <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> tab.length;<br>        <span class="hljs-comment">// 此时注意如果从上面情况`2.`进来时,</span><br>        <span class="hljs-comment">// e为空则直接返回null,不会进入while循环</span><br>        <span class="hljs-comment">// 只有e不为空且e.get() != key时才会进while循环</span><br>        <span class="hljs-keyword">while</span> (e != <span class="hljs-literal">null</span>) &#123;<br>            ThreadLocal&lt;?&gt; k = e.get();<br>            <span class="hljs-comment">// 找到相同的k,返回得到的Entry,get操作结束</span><br>            <span class="hljs-keyword">if</span> (k == key)<br>                <span class="hljs-keyword">return</span> e;<br>            <span class="hljs-comment">// 若此时的k为空,那么e则被标记为`Stale`需要被`expunge`</span><br>            <span class="hljs-keyword">if</span> (k == <span class="hljs-literal">null</span>)<br>                expungeStaleEntry(i);<br>            <span class="hljs-keyword">else</span><span class="hljs-comment">// 下面两个都是遍历的相关操作</span><br>                <span class="hljs-comment">// nextIndex就是+1判断是否越界</span><br>                i = nextIndex(i, len);<br>            e = tab[i];<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">null</span>;<br>&#125;<br></code></pre></div></td></tr></table></figure><blockquote><p><strong>在判断出现 hash 冲突之后，直接往后线性查找之后的数组元素。</strong></p></blockquote><br><br><h4><span id="expungestaleentryint-staleslot">expungeStaleEntry(int staleSlot)</span></h4><ul><li>该方法用来清除 <code>staleSlot</code> 位置的 Entry 对象,并且会<strong>清理当前节点到下一个 <code>null</code> 节点中间的过期 <code>Entry</code>.</strong></li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">/** </span><br><span class="hljs-comment">  * 清空旧的Entry对象</span><br><span class="hljs-comment">  * <span class="hljs-doctag">@param</span> staleSlot: 清理的起始位置</span><br><span class="hljs-comment">  * <span class="hljs-doctag">@param</span> return: 返回的是第一个为空的Entry下标</span><br><span class="hljs-comment">  */</span><br> <span class="hljs-keyword">private</span> <span class="hljs-type">int</span> <span class="hljs-title function_">expungeStaleEntry</span><span class="hljs-params">(<span class="hljs-type">int</span> staleSlot)</span> &#123;<br>         Entry[] tab = table;<br>         <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> tab.length;<br>     <span class="hljs-comment">// 清空`staleSlot`位置的Entry</span><br>     <span class="hljs-comment">// value引用置为空之后,对象被标记为不可达,下次GC就会被回收.</span><br>         tab[staleSlot].value = <span class="hljs-literal">null</span>;<br>         tab[staleSlot] = <span class="hljs-literal">null</span>;<br>         size--;<br>         Entry e;<br>         <span class="hljs-type">int</span> i;<br>     <span class="hljs-comment">// 通过nextIndex从`staleSlot`的下一个开始向后遍历Entry数组,直到e不为空</span><br>      <span class="hljs-comment">// e赋值为当前的Entry对象</span><br>         <span class="hljs-keyword">for</span> (i = nextIndex(staleSlot, len);<br>              (e = tab[i]) != <span class="hljs-literal">null</span>;<br>              i = nextIndex(i, len)) &#123;<br>             ThreadLocal&lt;?&gt; k = e.get();<br>             <span class="hljs-comment">// 当k为空的时候清空节点信息</span><br>             <span class="hljs-keyword">if</span> (k == <span class="hljs-literal">null</span>) &#123;<br>                 e.value = <span class="hljs-literal">null</span>;<br>                 tab[i] = <span class="hljs-literal">null</span>;<br>                 size--;<br>             &#125; <span class="hljs-keyword">else</span> &#123;<span class="hljs-comment">// 以下为k存在的情况</span><br>                 <span class="hljs-type">int</span> <span class="hljs-variable">h</span> <span class="hljs-operator">=</span> k.threadLocalHashCode &amp; (len - <span class="hljs-number">1</span>);<br>                 <span class="hljs-comment">// 元素下标和key计算的不一样，表明是出现`Hash碰撞`之后调整的位置</span><br>                 <span class="hljs-comment">// 将当前的元素移动到下一个null位置</span><br>                 <span class="hljs-keyword">if</span> (h != i) &#123;<br>                     tab[i] = <span class="hljs-literal">null</span>;<br>                     <span class="hljs-keyword">while</span> (tab[h] != <span class="hljs-literal">null</span>)<br>                         h = nextIndex(h, len);<br>                     tab[h] = e;<br>                 &#125;<br>             &#125;<br>         &#125;<br>         <span class="hljs-keyword">return</span> i;<br>     &#125; <br></code></pre></div></td></tr></table></figure><p>该方法是对内存泄露的进一步处理。</p><p><strong>如果将ThreadLocal的内存泄露问题分成两个部分来看，一个是 Key，另外一个就是 Value。</strong></p><p><strong>Key 的部分依靠弱引用清除，如果外部的强引用断开之后，也就是没有地方在使用到该 Key 之后，Key 会被 GC 回收，所以引用就为 null。</strong></p><p>从而判断 Key 为 null 的 Value 就是 Stale 的对象，则靠该方法清除。</p><blockquote><p>ThreadLocal 靠弱引用清除的只有 Key 对象，还有 Value 对象则需要靠扫描，所以内存泄露的情况并不是能够完全避免的。</p></blockquote><br><br><h3><span id="元素添加">元素添加</span></h3><h4><span id="setthreadlocalltgt-key-object-value">set(ThreadLocal&lt;?&gt; key, Object value)</span></h4><ul><li>该方法就是添加元素的方法。</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">set</span><span class="hljs-params">(ThreadLocal&lt;?&gt; key, Object value)</span> &#123;<br>    Entry[] tab = table;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> tab.length;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> key.threadLocalHashCode &amp; (len-<span class="hljs-number">1</span>);<br>    <span class="hljs-comment">// 整个循环的功能就是找到相同的key覆盖value</span><br>    <span class="hljs-comment">// 或者找到key为null的节点覆盖节点信息</span><br>    <span class="hljs-comment">// 只有在e==null的时候跳出循环执行下面的代码</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">Entry</span> <span class="hljs-variable">e</span> <span class="hljs-operator">=</span> tab[i];<br>         e != <span class="hljs-literal">null</span>;<br>         e = tab[i = nextIndex(i, len)]) &#123;<br>        ThreadLocal&lt;?&gt; k = e.get();<br>        <span class="hljs-comment">// 找到相等的k,则直接替换value,set操作结束</span><br>        <span class="hljs-keyword">if</span> (k == key) &#123;<br>            e.value = value;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-comment">// k为空表示该节点过期,直接替换该节点</span><br>        <span class="hljs-keyword">if</span> (k == <span class="hljs-literal">null</span>) &#123;       <span class="hljs-comment">// 1.</span><br>            replaceStaleEntry(key, value, i);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-comment">// 走到这一步就是找到了e为空的位置，不然在上面两个判断里都return了</span><br>    tab[i] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Entry</span>(key, value);<br>    <span class="hljs-type">int</span> <span class="hljs-variable">sz</span> <span class="hljs-operator">=</span> ++size;<br>    <span class="hljs-keyword">if</span> (!cleanSomeSlots(i, sz) &amp;&amp; sz &gt;= threshold)<br>        rehash();<br>&#125;<br></code></pre></div></td></tr></table></figure><p>通过 hashCode 确定下标后，如果 Key 相等则直接覆盖原数据，如果 Key 不相等则往后线性查找元素，找到为 null 的元素直接覆盖，或者找到空余的位置赋值。</p><br><p>最后会清理旧的元素，并且判断 threshold，决定是否需要扩容。</p><blockquote><p><strong>ThreadLocalMap 处理 Hash 冲突的方法叫做 线性寻址法，在冲突之后往后搜索，找到第一个为空的下标并保存元素。</strong></p><p>线性寻址法在出现 Hash 冲突的时候处理的复杂度基本会变成 O(n)，并不能直接找一个 null 点就存储，因为数组中可能还有相同的 Key 在后面。</p></blockquote><br><br><p>replaceStaleEntry</p><ul><li>源码中只有从上面 <code>1.</code> 处进入该方法,用于<strong>替换  <code>key</code>  为空的 <code>Entry</code> 节点,顺带清除数组中的过期节点.</strong></li></ul><p>往后搜索的是第一个为空或者 Key 相等，如果先找到 Key 为空的并不能保证后续的节点没有 Key 相等的，所以在 replaceStaleEntry 方法中可能还需要处理另外一个 Key 相同的节点。</p><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> *从`set.1.`处进入,key是插入元素ThreadLocal的hash,staleSlot为key为空的数组节点下标</span><br><span class="hljs-comment"> */</span><br><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">replaceStaleEntry</span><span class="hljs-params">(ThreadLocal&lt;?&gt; key, Object value,</span><br><span class="hljs-params">                               <span class="hljs-type">int</span> staleSlot)</span> &#123;<br>    Entry[] tab = table;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> tab.length;<br>    Entry e;<br>    <span class="hljs-type">int</span> <span class="hljs-variable">slotToExpunge</span> <span class="hljs-operator">=</span> staleSlot;<br>    <span class="hljs-comment">// 从传入位置,即插入时发现k为null的位置开始,向前遍历,直到数组元素为空</span><br>    <span class="hljs-comment">// 找到最前面一个key为null的值.</span><br>    <span class="hljs-comment">// 这里要吐槽一下源代码...大括号都不加 习惯真差</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> prevIndex(staleSlot, len);<br>         (e = tab[i]) != <span class="hljs-literal">null</span>;<br>         i = prevIndex(i, len))&#123;<br><span class="hljs-comment">// 向前获取到第一个 Key 为空的对象</span><br>        <span class="hljs-keyword">if</span> (e.get() == <span class="hljs-literal">null</span>)<br>            <span class="hljs-comment">// 因为是环状遍历所以此时slotToExpunge是可能等于staleSlot的</span><br>            slotToExpunge = i;<br>    &#125;<br>    <span class="hljs-comment">// 该段循环的功能就是向后遍历找到`key`相等的节点并替换</span><br>    <span class="hljs-comment">// 并对之后的元素进行清理</span><br>    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">i</span> <span class="hljs-operator">=</span> nextIndex(staleSlot, len);<br>         (e = tab[i]) != <span class="hljs-literal">null</span>;<br>         i = nextIndex(i, len)) &#123;<br>        ThreadLocal&lt;?&gt; k = e.get();<br>        <span class="hljs-keyword">if</span> (k == key) &#123;<br>            <span class="hljs-comment">// 替换 e 的 value</span><br>            e.value = value;<br>            <span class="hljs-comment">// staleSlot 是因为 key 为 null 才进来的</span><br>            <span class="hljs-comment">// 所以 tab[i] 也是需要清理的节点</span><br>            tab[i] = tab[staleSlot];<br>            tab[staleSlot] = e;<br>            <span class="hljs-keyword">if</span> (slotToExpunge == staleSlot)<br>                slotToExpunge = i;<br>            cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-comment">// 其实我对这个`slotToExpunge == staleSlot`的判断一直挺疑惑的,为什么需要这个判断?</span><br>        <span class="hljs-keyword">if</span> (k == <span class="hljs-literal">null</span> &amp;&amp; slotToExpunge == staleSlot)<br>            slotToExpunge = i;<br>    &#125;<br>    <span class="hljs-comment">// e==null时跳到下面代码运行</span><br>    <span class="hljs-comment">// 清空并重新赋值</span><br>    <span class="hljs-comment">// 断开 Entry 对应的数据的强引用</span><br>    tab[staleSlot].value = <span class="hljs-literal">null</span>;<br>    tab[staleSlot] = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Entry</span>(key, value);<br>    <span class="hljs-comment">// set后的清理</span><br>    <span class="hljs-keyword">if</span> (slotToExpunge != staleSlot)<br>        cleanSomeSlots(expungeStaleEntry(slotToExpunge), len);<br>&#125;<br><br></code></pre></div></td></tr></table></figure><p><strong>如上所说，再出现 Hash 冲突的时候，往后搜索的是第一个为空的节点，并不能直接赋值，因为在后续的数组中可能还存在相同的 Key 的节点。</strong></p><p>替换元素之前会先向前搜索找到一个 Key 为 null 的节点。</p><br><br><h4><span id="cleansomeslots">cleanSomeSlots</span></h4><ul><li>该方法的功能是就是清除数组中的过期<code>Entry</code></li><li>首次清除从<code>i</code>向后开始遍历<code>log2(n)</code>次,如果之间发现过期<code>Entry</code>会直接将<code>n</code>扩充到<code>len</code>可以说全数组范围的遍历.发现过期<code>Entry</code>就调用<code>expungeStaleEntry</code>清除直到未发现<code>Entry</code>为止.</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">/**</span><br><span class="hljs-comment">  * <span class="hljs-doctag">@param</span> i 清除的起始节点位置</span><br><span class="hljs-comment">  * <span class="hljs-doctag">@param</span> n 遍历控制,每次扫描都是log2(n)次,一般取当前数组的`size`或`len`</span><br><span class="hljs-comment">  */</span><br><span class="hljs-keyword">private</span> <span class="hljs-type">boolean</span> <span class="hljs-title function_">cleanSomeSlots</span><span class="hljs-params">(<span class="hljs-type">int</span> i, <span class="hljs-type">int</span> n)</span> &#123;<br>    <span class="hljs-comment">// 是否有清除的标记</span><br>            <span class="hljs-type">boolean</span> <span class="hljs-variable">removed</span> <span class="hljs-operator">=</span> <span class="hljs-literal">false</span>;<br>    <span class="hljs-comment">// 获取底层数组的数据信息</span><br>            Entry[] tab = table;<br>            <span class="hljs-type">int</span> <span class="hljs-variable">len</span> <span class="hljs-operator">=</span> tab.length;<br>            <span class="hljs-keyword">do</span> &#123;<br>                i = nextIndex(i, len);<br>                <span class="hljs-type">Entry</span> <span class="hljs-variable">e</span> <span class="hljs-operator">=</span> tab[i];<br>                <span class="hljs-keyword">if</span> (e != <span class="hljs-literal">null</span> &amp;&amp; e.get() == <span class="hljs-literal">null</span>) &#123;<br>                    <span class="hljs-comment">// 当发现有过期`Entry`时,n变为len</span><br>                    <span class="hljs-comment">// 即扩大范围,全数组范围在遍历一次</span><br>                    n = len;<br>                    removed = <span class="hljs-literal">true</span>;<br>                    i = expungeStaleEntry(i);<br>                &#125;<br>                <span class="hljs-comment">// 无符号右移一位相当于n = n /2</span><br>                <span class="hljs-comment">// 所以在第一次会遍历`log2(n)`次</span><br>            &#125; <span class="hljs-keyword">while</span> ( (n &gt;&gt;&gt;= <span class="hljs-number">1</span>) != <span class="hljs-number">0</span>);<br>    <span class="hljs-comment">// 遍历过程中没出现过期`Entry`的情况下会返回是否有清理的标记.</span><br>            <span class="hljs-keyword">return</span> removed;<br>        &#125;<br></code></pre></div></td></tr></table></figure><br><br><h3><span id="扩容调整方法">扩容调整方法</span></h3><h4><span id="rehash">rehash</span></h4><ul><li>容量调整的先驱方法,先清理过期<code>Entry</code>,并做是否需要<code>resize</code>的判断</li><li>调整的条件是<strong>当前size大于阈值的3&#x2F;4</strong>就进行扩容</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">rehash</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-comment">// 清理过期Entry</span><br>           expungeStaleEntries();<br>    <span class="hljs-comment">// 初始阈值threshold为10</span><br>           <span class="hljs-keyword">if</span> (size &gt;= threshold - threshold / <span class="hljs-number">4</span>)<br>               resize();<br>       &#125;<br></code></pre></div></td></tr></table></figure><br><br><h4><span id="resize">resize</span></h4><ul><li>扩容的实际方法.</li></ul><figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-keyword">private</span> <span class="hljs-keyword">void</span> <span class="hljs-title function_">resize</span><span class="hljs-params">()</span> &#123;<br>    <span class="hljs-comment">// 获取旧数组并记录就数组大小</span><br>          Entry[] oldTab = table;<br>          <span class="hljs-type">int</span> <span class="hljs-variable">oldLen</span> <span class="hljs-operator">=</span> oldTab.length;<br>    <span class="hljs-comment">// 新数组大小为旧数组的两倍</span><br>          <span class="hljs-type">int</span> <span class="hljs-variable">newLen</span> <span class="hljs-operator">=</span> oldLen * <span class="hljs-number">2</span>;<br>          Entry[] newTab = <span class="hljs-keyword">new</span> <span class="hljs-title class_">Entry</span>[newLen];<br>          <span class="hljs-type">int</span> <span class="hljs-variable">count</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>;<br><span class="hljs-comment">// 遍历整个旧数组,并迁移元素到新数组</span><br>          <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> <span class="hljs-variable">j</span> <span class="hljs-operator">=</span> <span class="hljs-number">0</span>; j &lt; oldLen; ++j) &#123;<br>              <span class="hljs-type">Entry</span> <span class="hljs-variable">e</span> <span class="hljs-operator">=</span> oldTab[j];<br>              <span class="hljs-comment">// 判断是否为空,空的话就算了</span><br>              <span class="hljs-keyword">if</span> (e != <span class="hljs-literal">null</span>) &#123;<br>                  ThreadLocal&lt;?&gt; k = e.get();<br>                  <span class="hljs-comment">// k为空即表示为过期节点,当即清理了.</span><br>                  <span class="hljs-keyword">if</span> (k == <span class="hljs-literal">null</span>) &#123;<br>                      e.value = <span class="hljs-literal">null</span>; <br>                  &#125; <span class="hljs-keyword">else</span> &#123;<br>                      <span class="hljs-comment">// 重新计算数组下标,如果数组对应位置已存在元素</span><br>                      <span class="hljs-comment">// 则环状遍历整个数组找个空位置赋值</span><br>                      <span class="hljs-type">int</span> <span class="hljs-variable">h</span> <span class="hljs-operator">=</span> k.threadLocalHashCode &amp; (newLen - <span class="hljs-number">1</span>);<br>                      <span class="hljs-keyword">while</span> (newTab[h] != <span class="hljs-literal">null</span>)<br>                          h = nextIndex(h, newLen);<br>                      newTab[h] = e;<br>                      count++;<br>                  &#125;<br>              &#125;<br>          &#125;<br><span class="hljs-comment">// 设置新属性</span><br>          setThreshold(newLen);<br>          size = count;<br>          table = newTab;<br>      &#125;<br></code></pre></div></td></tr></table></figure><br><br><h2><span id="qampa">Q&amp;A</span></h2><blockquote><p>Q: ThreadLocal 为何会出现内存泄露？</p></blockquote><p><strong>ThreadLocal 会出现内存泄露的主要原因是如果是强引用，那么在 ThreadLocal 类不再使用之后，ThreadLocalMap 中无法清除相关的 Entry 对象。</strong></p><p>在 ThreadLocal 不再使用之后，ThreadLocalMap 中指向 ThreadLocal 的强引用也会导致 ThreadLocal 无法被 GC 回收，同理 Value 对象也被保留了下来。</p><p><strong>也就出现了所谓的内存泄露，无用的数据无法被 GC 有效的清除。</strong></p><br><br><blockquote><p> Q: ThreadLocal 如何解决内存泄漏?</p></blockquote><p>ThreadLocal 的内存泄露可以分为 Key（也就是 ThreadLocal），以及 Value。</p><p><strong>解决 Key 的内存泄露的方法就是采用弱引用，弱引用消除了 ThreadLocalMap 对 ThreadLocal 对象的 GC 的影响。</strong></p><p>另外的在每次获取或者添加数据的时候都会判断 Key 是否被回收，如果 Key 已经被回收会连带清理 Value 对象，这也就顺带解决了 Value 的泄露问题。</p><br><br><blockquote><p> Q: ThreadLocalMap 如何解决Hash冲突？</p></blockquote><p>Hash 冲突就是指通过 Hash 计算的下标值一致，两个元素的定位一致。</p><p>HashMap 解决 Hash 冲突的方法就是<strong>拉链法</strong>，底层的数组中保存的不是单一的数据，而是一个集合(链表&#x2F;红黑树)，冲突之后下挂。</p><p>采用拉链法的结果就是在Hash冲突严重时会严重影响时间复杂度，因为就算是红黑树查询的事件复杂度都是 O(Log2n)。</p><p>ThreadLocalMap 并没有采用这种方法，而是使用的<strong>开放寻址法</strong>，如果已经有数据存在冲突点，就在数组中往下遍历找到第一个空着的位置。</p><blockquote><p>需要注意的是，并不是找到空的位置就可以直接替换，还是需要遍历整个数组确保没有重复的 Key。</p></blockquote><br><br><blockquote><p> Q: ThreadLocalMap 和 HashMap 的异同</p></blockquote><p>两个都是采用 Hash 定位的数据结构，底层都是以数组的形式。</p><p>但是 HashCode 的获取方式不同，HashMap 调用对象的 hashCode() 方法，而  ThreadLocalMap 中的 Key 就是 ThreadLocal，ThreadLocal 的 HashCode 是递增分配的。</p><p>另外处理 Hash 冲突的方式不同，ThreadLocalMap 采用的开放寻址法，而 HashMap 采用的是拉链法。</p>]]></content>
    
    
    <categories>
      
      <category>java</category>
      
    </categories>
    
    
    <tags>
      
      <tag>jdk</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>浅析 Redis 的主从模式</title>
    <link href="/2021/05/28/%E6%B5%85%E8%B0%88Redis%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%BC%8F/"/>
    <url>/2021/05/28/%E6%B5%85%E8%B0%88Redis%E7%9A%84%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%E6%A8%A1%E5%BC%8F/</url>
    
    <content type="html"><![CDATA[<h1><span id="redis-的主从复制">Redis 的主从复制</span></h1><h2><span id="概述">概述</span></h2><p>Redis 的主从复制是 Redis 官方推出的分布式机制，解决了部分集群问题。</p><p>官方后续的一些分布式的实现，包括 Sentinel 以及 Cluster 等，多多少少都用到了复制的功能。</p><h2><span id="思维脑图">思维脑图</span></h2><p><img src="/assets/redis-master-slaver-7942494.png" alt="redis-master-slaver"></p><h2><span id="相关实现">相关实现</span></h2><h3><span id="查看节点主从信息">查看节点主从信息</span></h3><p>通过指令 <code>info replication</code>，可以单独查看服务器此时的主从信息。如下：</p><p><img src="/assets/redis_info_replication_master-7942497.png" alt="redis-info-replication"></p><blockquote><p>role 表示当前节点的身份，master 表示是主节点</p><p>connected_slave 表示当前的子节点数，以及 slave0 就表示子节点信息。</p></blockquote><br><h3><span id="主从关系的建立">主从关系的建立</span></h3><p>Redis 服务器可以通过 <code>SLAVEOF &lt;ip&gt; &lt;port&gt;</code> 命令或者配置文件中 <code>slavof &lt;ip&gt; &lt;port&gt;</code> 的方式，建立主从关系。</p><p>被复制的服务器称为主服务器，当前服务器则称为从服务器。</p><p>需要注意的是，Redis 只支持一主多从的方式，一个从服务器只能对应一个主服务器。</p><br><p><strong>建立主从关系之后，从服务器就无法再执行写命令了，而是完全同步主服务器的数据。</strong></p><blockquote><p>即使在执行 AOF 或者 RDB 文件的过程中发现有过期的键也不会主动删除，只能等主服务器的同步。</p><p>因为无法执行命令，无法写入，所以<strong>主从模式仅仅只扩展了读属性，写入瓶颈依然存在。</strong></p></blockquote><br><p>该种主从复制模型非常适合读多写少的环境，复制相当于为主服务器中的数据创建多个复本，也算是一种<strong>容错策略</strong>。</p><p>单点的写入也一定程度上保证了一致性的要求。</p><blockquote><p>这里的一致性都是指最终一致性，<strong>因为命令的扩散也会有延迟</strong>，卡着延迟从从服务器中读取就会有数据不一致的问题。</p><p>因此如果对一致性的要求很高，或者必须要强一致性，建议不要从从服务器读取。</p></blockquote><p>复制模式可以分为<strong>数据同步</strong>以及<strong>命令传播</strong>两个阶段。</p><p>数据同步就是从服务器刚开始连接时的操作，全盘同步主服务器上的数据。</p><p>命令传播就是主服务器将本地执行过的命令再发送到从服务器(主服务器以客户端的身份发送命令到从服务器)。</p><br><p><strong>Redis 中对应数据同步的命令有两个 SYNC 和 PSYNC。</strong></p><h3><span id="sync-旧版复制">SYNC - 旧版复制</span></h3><p>旧版的数据同步就是依托于 SYNC 命令，从服务器向主服务器发送该命令表示开启同步数据流程。</p><p><img src="/assets/Redis_SYNC_%E6%B5%81%E7%A8%8B-7942500.png" alt="redis-sync基础流程"></p><p>主服务器首次接收到 <code>SYNC</code> 命令之后，会执行 BGSAVE 命令生成 RDB 文件，并在此时开启<strong>命令缓冲区</strong>，记录备份期间所有执行的写命令。</p><p>BGSAVE 执行完之后，会将生成的RDB文件发送给从服务器。</p><blockquote><p>此时如果于多个从服务器连接，RDB 文件是可以直接共享的。</p></blockquote><p>从服务器在接收到主服务器发送的 RDB 文件之后，会清空本地的所有数据，全盘载入 RDB 文件中的数据。</p><p>之后主服务器还会将缓冲区中的数据发送到从服务器，从服务器执行完缓冲区中的写命令，就达到了和主服务器的完全一致。</p><br><blockquote><p>旧版的复制很简单，主要就是生成 RDB 文件并传播指令。</p><p>问题就在于太过简单，<strong>即使网络波动导致的瞬时断连，在重连之后也会进行全量同步。</strong></p></blockquote><br><h3><span id="psync-新版本的数据同步">PSYNC - 新版本的数据同步</span></h3><p>PSYNC 命令是对 SYNC 命令的进一步优化，主要是 SYNC 只能进行全量同步，效率真的就不高，为此在 Redis2.8 版本之后，新增加了一个 PSYNC 命令。</p><p>PSYNC 命令完整的形式是 <code>PSYNC &lt;runid&gt; &lt;offest&gt;</code>，<strong>在全量同步的基础上增加了一个增量同步的过程判断。</strong></p><br><p>下面是增量同步中增加的概念：</p><ol><li><p>复制偏移量</p><p>按照字面意思也很好理解，是主从服务器各自维护的<strong>以字节为单位</strong>的属性，表示复制的进度。</p><p>比如当前主服务器的复制偏移量为10000，在发送了50个字节的内容之后，就变为了10050，可以认为是主从服务器数据不一致性程度的表示。</p><p>在 Sentinel 执行故障转移的时候也会以复制偏移量作为主要的参考依据。</p><blockquote><p>一定程度上，复制偏移量就表示从节点数据的完整性。</p></blockquote><br></li><li><p>复制缓冲区</p><p>复制缓冲区是由主服务器维护的一个固定长度的 FIFO 队列，该队列会缓存近期主服务器所执行的写命令。</p><br></li><li><p>主服务器 run ID</p><p>run ID 唯一标识一个 Redis 服务器。</p><p>实际上不论主从在服务器启动时都会生成一个 run ID，由40位随机的16进制字符组成。</p><p>此处的 run ID 是在从服务器连接到主服务器是由主服务器下发的自身的 run ID，重连之后通过判断 run ID 来确定是否为同一个 Master。</p></li></ol><br><p>PSYNC 的执行流程简述如下：</p><ol><li>判断 run ID 是否相同，不相同会直接开启全量同步的逻辑，相当于直接走 SYNC。</li><li>run ID 相同表示是断线重连，判断复制偏移量是否还在复制缓冲区中，如果超出表示超时时间过长，也需要走 SYNC。</li><li>如果复制偏移量未超出复制缓冲区，则直接将复制缓冲区中的命令发送到从服务器，从而避免全量同步。</li></ol><br><h2><span id="qampa">Q&amp;A</span></h2><blockquote><p>Q: 主从模式的优势</p></blockquote><p>横向扩展了读性能</p><p>备份数据，强化数据安全</p><br><blockquote><p>Q: 主从模式的存在的问题</p></blockquote><p>对于写性能并没有提高，可能出于一致性的考虑，Redis 的主从模式并不允许从从服务器写入。</p><p>非强一致性，命令的扩散存在一定的延时，此时主从的数据并不一致。</p><p>单点故障问题，因为只能从主节点写入，单点故障问题很难避免，只要主节点宕机，整个集群就不可写入。</p><br><blockquote><p>Q: PSYNC 的优化</p></blockquote><p>PSYNC 借由复制缓冲区实现了对断线重连的容忍机制，如果断线时间断，可以从复制缓冲区中找到缺失的命令就可以进行部分重同步，而避免每次都是全量同步。</p>]]></content>
    
    
    <categories>
      
      <category>redis</category>
      
    </categories>
    
    
    <tags>
      
      <tag>redis</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
